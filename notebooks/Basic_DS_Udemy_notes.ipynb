{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "## Unsupervised learning\n",
    "\n",
    "* Attempts to split data into K groups that are closest to K centroids.\n",
    "\n",
    "    * (1)Centroids are adjusted to the center of the points that were closest to it.\n",
    "\n",
    "    * (2)Points are then used to find which centroids they are closest to again.\n",
    "\n",
    "* repeat 1 & 2 until error or distance centroids move converges.\n",
    "\n",
    "### Caveats\n",
    "\n",
    "* choosing K\n",
    "    * try increasing K until you stop getting large reductions in $\\chi^2$\n",
    "    \n",
    "* use different randomly chosen initial centroids to avoid local minima\n",
    "\n",
    "* Still need to determine labels for clusters found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy \n",
    "\n",
    "* A measure of a data set's disorder - how same or different it is.  \n",
    "* Classify data set into N classes.\n",
    "    * Entropy of 0, implies all data is the same class\n",
    "    * High entropy, implies there are many types of classes in the data\n",
    "\n",
    "### Computing Entropy\n",
    "\n",
    "* $H(s) = -p_1ln(p_1) -...-p_nln(p_n)$\n",
    "* $p_i$ represents portion of data with that class/label\n",
    "* casses where all data is or all data is not a particular class contribute zero to entropy.  So, non-zero only when portions of the data are in different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.5.1-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "* flowcharts to assist with classification choices\n",
    "* EX. A tree of resume contents organized by its relation to the chances of being hired.\n",
    "\n",
    "## Random Forests\n",
    "\n",
    "#### Can use 'from sklearn import tree',  AND pandas to organize data going into the trees.  Graphviz can be used to visualize resulting trees.\n",
    "\n",
    "* Decision trees are very susceptible to overfitting\n",
    "    * construct many trees in a 'forest' and have them all 'vote' towards the outcome classification\n",
    "         * MUST randomly sample data used to make each tree!\n",
    "         * Also, randomize the attributes each tree is fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
