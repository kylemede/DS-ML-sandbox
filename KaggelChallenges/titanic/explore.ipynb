{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My playing with the Kaggle titanic challenge.\n",
    "\n",
    "I COPPIED THE INITIAL CODE and got lots of the ideas for this first Kaggle advanture from [here](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic/comments).\n",
    "\n",
    "I will later compact the important stuff from here into a kernal on my Kaggle account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\",dtype={\"Age\":np.float64},)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many ages\n",
    "train_df['Age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many ages are NaN?\n",
    "train_df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age =  29.6792717087\n"
     ]
    }
   ],
   "source": [
    "# plot ages of training data set, with NaN's removed\n",
    "if False:\n",
    "    train_df['Age'].dropna().astype(int).hist(bins=70)\n",
    "print 'Mean age = ',train_df['Age'].dropna().astype(int).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see where they got on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x=\"Embarked\",data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x='Survived',hue='Embarked',data=train_df,order=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so clearly there were more people who got on at S, and it seems their survival is disproportional.  Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    embark_survive_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "    sns.barplot(x='Embarked', y='Survived', data=embark_survive_perc,order=['S','C','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting, actually those from C had higher rate of survival.  So, knowing more people from your home town didn't help.\n",
    "\n",
    "## Next, did how much they paid have an effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_df['Fare'].astype(int).plot(kind='hist',bins=100, xlim=(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get fare for survived & didn't survive passengers \n",
    "if False:\n",
    "    fare_not_survived = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 0]\n",
    "    fare_survived     = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 1]\n",
    "\n",
    "    # get average and std for fare of survived/not survived passengers\n",
    "    avgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "    std_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "    avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
    "    avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before digging into how the ages factor in, let's take the advice of others and replace NaN's with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  80.0\n",
      "min:  0.42\n",
      "After this gaussian replacment, there are:  0\n",
      "max:  80.0\n",
      "min:  0.42\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = train_df['Age'].min(), train_df['Age'].max()\n",
    "mu, sigma = train_df[\"Age\"].mean(), train_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = train_df.shape[0]\n",
    "\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(train_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = train_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "train_df['Age'] = rands\n",
    "\n",
    "\"\"\"\n",
    "## we will make a new column with Nan's replaced, then push that into the original df\n",
    "n = train_df.shape[0] # number of rows\n",
    "#randy = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = n)\n",
    "# draw from a gaussian instead of simple uniform\n",
    "# note this uses a 'standard gauss' and that tneeds to have its var and mean shifted\n",
    "randy = np.random.randn(n)*std_age_train + average_age_train\n",
    "idx = np.isfinite(train_df['Age']) # gives a boolean index for the NaNs in the df's column\n",
    "randy[idx.values] = train_df[idx]['Age'].values  ## idexing the values of randy with this\n",
    "#now have updated column, next push into original df\n",
    "train_df['Age'] = randy\n",
    "\"\"\"\n",
    "\n",
    "print 'After this gaussian replacment, there are: ',train_df['Age'].isnull().sum()\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot new Age Values\n",
    "if False:\n",
    "    train_df['Age'].hist(bins=70)\n",
    "# Compare this to that from a few cells up for the raw ages with the NaN's dropped.  Not much different actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets perform the same NaN replacement for the 'Age' with the test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## let's pull in the test data\n",
    "test_df = pd.read_csv(\"test.csv\",dtype={\"Age\":np.float64},)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  76.0\n",
      "min:  0.17\n"
     ]
    }
   ],
   "source": [
    "#### Do the same for the test data\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = test_df['Age'].min(), test_df['Age'].max()\n",
    "mu, sigma = test_df[\"Age\"].mean(), test_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = test_df.shape[0]\n",
    "\n",
    "print 'max: ',test_df['Age'].max()\n",
    "print 'min: ',test_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(test_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = test_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "test_df['Age'] = rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df['Age'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's make a couple nice plots of survival vs age\n",
    "# peaks for survived/not survived passengers by their age\n",
    "if False:\n",
    "    facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\n",
    "    #facet.map(sns.kdeplot,'Age',shade= True) # This keeps crashing the kernal, but I don't know why!!!!!!!!!!\n",
    "    facet.set(xlim=(0, train_df['Age'].astype(int).max()))\n",
    "    facet.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average survived passengers by age\n",
    "if False:\n",
    "    fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "    average_age = train_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "    sns.barplot(x='Age', y='Survived', data=average_age)\n",
    "    print 'max: ',train_df['Age'].astype(int).max()\n",
    "    print 'min: ',train_df['Age'].astype(int).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "if False:\n",
    "    # It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
    "    train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "    test_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "## OR convert NaNs to 'U' meaning 'Unknown' and map all to new columns\n",
    "if True:\n",
    "    # Code based on that here: http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    train_df.Cabin.fillna('U',inplace=True)\n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    train_df['Cabin'] = train_df['Cabin'].map(lambda c : c[0])\n",
    "    # dummy encoding ...\n",
    "    cabin_dummies = pd.get_dummies(train_df['Cabin'],prefix='Cabin')\n",
    "    train_df = pd.concat([train_df,cabin_dummies],axis=1)\n",
    "    train_df.drop('Cabin',axis=1,inplace=True)\n",
    "    \n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    test_df.Cabin.fillna('U',inplace=True)\n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    test_df['Cabin'] = test_df['Cabin'].map(lambda c : c[0])\n",
    "    # dummy encoding ...\n",
    "    cabin_dummies = pd.get_dummies(test_df['Cabin'],prefix='Cabin')\n",
    "    test_df = pd.concat([test_df,cabin_dummies],axis=1)\n",
    "    test_df.drop('Cabin',axis=1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function introduces 4 new features:\n",
    "\n",
    "- FamilySize : the total number of relatives including the passenger (him/her)self.\n",
    "- Sigleton : a boolean variable that describes families of size = 1\n",
    "- SmallFamily : a boolean variable that describes families of 2 <= size <= 4\n",
    "- LargeFamily : a boolean variable that describes families of 5 < size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Family\n",
    "\n",
    "# Code based on that here: http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\n",
    "# introducing a new feature : the size of families (including the passenger)\n",
    "train_df['FamilySize'] = train_df['Parch'] + train_df['SibSp'] + 1\n",
    "# introducing other features based on the family size\n",
    "train_df['Singleton'] = train_df['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "train_df['SmallFamily'] = train_df['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "train_df['LargeFamily'] = train_df['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
    "\n",
    "# Code based on that here: http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\n",
    "# introducing a new feature : the size of families (including the passenger)\n",
    "test_df['FamilySize'] = test_df['Parch'] + test_df['SibSp'] + 1\n",
    "# introducing other features based on the family size\n",
    "test_df['Singleton'] = test_df['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "test_df['SmallFamily'] = test_df['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "test_df['LargeFamily'] = test_df['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
    "\n",
    "if False:\n",
    "\n",
    "    # Instead of having two columns Parch & SibSp, \n",
    "    # we can have only one column represent if the passenger had any family member aboard or not,\n",
    "    # Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
    "    train_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\n",
    "    train_df['Family'].loc[train_df['Family'] > 0] = 1\n",
    "    train_df['Family'].loc[train_df['Family'] == 0] = 0\n",
    "\n",
    "    test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
    "    test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
    "    test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
    "\n",
    "    # drop Parch & SibSp\n",
    "    train_df = train_df.drop(['SibSp','Parch'], axis=1)\n",
    "    test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
    "\n",
    "# plot\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Family',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Family', data=train_df, order=[1,0], ax=axis1)\n",
    "\n",
    "    # average of survived for those who had/didn't have any family member\n",
    "    family_perc = train_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\n",
    "    sns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n",
    "\n",
    "    axis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "\n",
    "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as males, females, and child\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "train_df['Person'] = train_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# No need to use Sex column since we created Person column\n",
    "train_df.drop(['Sex'],axis=1,inplace=True)\n",
    "test_df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "# create dummy variables for Person column\n",
    "person_dummies_titanic  = pd.get_dummies(train_df['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "#person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "#person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(person_dummies_titanic)\n",
    "test_df    = test_df.join(person_dummies_test)\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Person',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Person', data=train_df, ax=axis1)\n",
    "\n",
    "    # average of survived for each Person(male, female, or child)\n",
    "    person_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
    "    sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
    "\n",
    "train_df.drop(['Person'],axis=1,inplace=True)\n",
    "test_df.drop(['Person'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not surprising, woman and children had higher survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pclass\n",
    "\n",
    "# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\n",
    "if False:\n",
    "    sns.factorplot('Pclass','Survived',order=[1,2,3], data=train_df,size=5)\n",
    "\n",
    "# create dummy variables for Pclass column\n",
    "pclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "#pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "#pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train_df = train_df.join(pclass_dummies_titanic)\n",
    "test_df    = test_df.join(pclass_dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ticket\n",
    "# Code based on that here: http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\n",
    "# a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "def cleanTicket(ticket):\n",
    "    ticket = ticket.replace('.','')\n",
    "    ticket = ticket.replace('/','')\n",
    "    ticket = ticket.split()\n",
    "    ticket = map(lambda t : t.strip() , ticket)\n",
    "    ticket = filter(lambda t : not t.isdigit(), ticket)\n",
    "    if len(ticket) > 0:\n",
    "        return ticket[0]\n",
    "    else: \n",
    "        return 'XXX'\n",
    "    \n",
    "train_df['Ticket'] = train_df['Ticket'].map(cleanTicket)\n",
    "tickets_dummies = pd.get_dummies(train_df['Ticket'],prefix='Ticket')\n",
    "train_df = pd.concat([train_df, tickets_dummies],axis=1)\n",
    "train_df.drop('Ticket',inplace=True,axis=1)\n",
    "\n",
    "test_df['Ticket'] = test_df['Ticket'].map(cleanTicket)\n",
    "tickets_dummies = pd.get_dummies(test_df['Ticket'],prefix='Ticket')\n",
    "test_df = pd.concat([test_df, tickets_dummies],axis=1)\n",
    "test_df.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Title\n",
    "# a map of more aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                    }\n",
    "# we extract the title from each name\n",
    "train_df['Title'] = train_df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# we map each title\n",
    "train_df['Title'] = train_df.Title.map(Title_Dictionary)\n",
    "#train_df.head()\n",
    "# we extract the title from each name\n",
    "test_df['Title'] = test_df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# we map each title\n",
    "test_df['Title'] = test_df.Title.map(Title_Dictionary)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encoding in dummy variable\n",
    "titles_dummies = pd.get_dummies(train_df['Title'],prefix='Title')\n",
    "train_df = pd.concat([train_df,titles_dummies],axis=1)\n",
    "titles_dummies = pd.get_dummies(test_df['Title'],prefix='Title')\n",
    "test_df = pd.concat([test_df,titles_dummies],axis=1)\n",
    "# removing the title variable\n",
    "train_df.drop('Title',axis=1,inplace=True)\n",
    "test_df.drop('Title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert categorical column values to ordinal for model fitting\n",
    "if False:\n",
    "    le_title = LabelEncoder()\n",
    "    # To convert to ordinal:\n",
    "    train_df.Title = le_title.fit_transform(train_df.Title)\n",
    "    test_df.Title = le_title.fit_transform(test_df.Title)\n",
    "    # To convert back to categorical:\n",
    "    #train_df.Title = le_title.inverse_transform(train_df.Title)\n",
    "    #train_df.head()\n",
    "    #test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also unsurprising.  The higher the booking class, then higher the chances to survive.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Now lets get to actually training and building a model to make predictions with!\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problems with the raw data\n",
    "- a couple NaNs in 'Embarked', so drop column\n",
    "- 'Name' strings can't be converted to anything useful, so drop column\n",
    "- replace NaNs in 'Fare' with median\n",
    "- 'Ticket' can't be converted to anything useful, so drop column\n",
    "- 'PassengerID' has no importance, so drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "# only for test_df, since there is a missing \"Fare\" values\n",
    "# could use mean or median here.\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\n",
    "train_df.drop(['Name'], axis=1,inplace=True)\n",
    "test_df.drop(['Name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['Ticket'], axis=1,inplace=True)\n",
    "#test_df.drop(['Ticket'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['PassengerId'], axis=1,inplace=True)\n",
    "#test_df.drop(['PassengerId'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "# Either to consider Embarked column in predictions,\n",
    "# and remove \"S\" dummy variable, \n",
    "# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n",
    "\n",
    "# OR, don't create dummy variables for Embarked column, just drop it, \n",
    "# because logically, Embarked doesn't seem to be useful in prediction.\n",
    "\n",
    "embark_dummies_train  = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_train.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n",
    "#embark_dummies_test.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(embark_dummies_train)\n",
    "test_df    = test_df.join(embark_dummies_test)\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The names are also pointless, so drop them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Scale all features except passengerID\n",
    "features = list(train_df.columns)\n",
    "features.remove('PassengerId')\n",
    "train_df[features] = train_df[features].apply(lambda x: x/x.max(), axis=0)\n",
    "\n",
    "features = list(test_df.columns)\n",
    "features.remove('PassengerId')\n",
    "test_df[features] = test_df[features].apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_XXX</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived     Age  SibSp  Parch      Fare  Cabin_A  Cabin_B  \\\n",
       "0            1       0.0  0.2750  0.125    0.0  0.014151      0.0      0.0   \n",
       "1            2       1.0  0.4750  0.125    0.0  0.139136      0.0      0.0   \n",
       "2            3       1.0  0.3250  0.000    0.0  0.015469      0.0      0.0   \n",
       "3            4       1.0  0.4375  0.125    0.0  0.103644      0.0      0.0   \n",
       "4            5       0.0  0.4375  0.000    0.0  0.015713      0.0      0.0   \n",
       "\n",
       "   Cabin_C  Cabin_D ...   Ticket_XXX  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0      0.0      0.0 ...          0.0           0.0         0.0       1.0   \n",
       "1      1.0      0.0 ...          0.0           0.0         0.0       0.0   \n",
       "2      0.0      0.0 ...          0.0           0.0         1.0       0.0   \n",
       "3      1.0      0.0 ...          1.0           0.0         0.0       0.0   \n",
       "4      0.0      0.0 ...          1.0           0.0         0.0       1.0   \n",
       "\n",
       "   Title_Mrs  Title_Officer  Title_Royalty    C    Q    S  \n",
       "0        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "1        1.0            0.0            0.0  1.0  0.0  0.0  \n",
       "2        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "3        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "4        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_XXX</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId       Age  SibSp     Parch      Fare  Cabin_A  Cabin_B  \\\n",
       "0          892  0.453947  0.000  0.000000  0.015282      0.0      0.0   \n",
       "1          893  0.618421  0.125  0.000000  0.013663      0.0      0.0   \n",
       "2          894  0.815789  0.000  0.000000  0.018909      0.0      0.0   \n",
       "3          895  0.355263  0.000  0.000000  0.016908      0.0      0.0   \n",
       "4          896  0.289474  0.125  0.111111  0.023984      0.0      0.0   \n",
       "\n",
       "   Cabin_C  Cabin_D  Cabin_E ...   Ticket_XXX  Title_Master  Title_Miss  \\\n",
       "0      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "1      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "2      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "3      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "4      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Officer  Title_Royalty    C    Q    S  \n",
       "0       1.0        0.0            0.0            0.0  0.0  1.0  0.0  \n",
       "1       0.0        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "2       1.0        0.0            0.0            0.0  0.0  1.0  0.0  \n",
       "3       1.0        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "4       0.0        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match up dataframe columns, by removing extras not in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ticket_A' not in training columns, so removing it from test df\n",
      "'Ticket_AQ3' not in training columns, so removing it from test df\n",
      "'Ticket_AQ4' not in training columns, so removing it from test df\n",
      "'Ticket_LP' not in training columns, so removing it from test df\n",
      "'Ticket_SCA3' not in training columns, so removing it from test df\n",
      "'Ticket_STONOQ' not in training columns, so removing it from test df\n"
     ]
    }
   ],
   "source": [
    "## Remove extra columns in training DF that are not in test DF\n",
    "train_cs = list(train_df.columns)\n",
    "train_cs.remove('Survived')\n",
    "test_cs = list(test_df.columns)\n",
    "for c in train_cs:\n",
    "    if c not in test_cs:\n",
    "        print repr(c)+' not in test columns, so removing it from training df'\n",
    "        train_df.drop([c], axis=1,inplace=True)\n",
    "for c in test_cs:\n",
    "    if c not in train_cs:\n",
    "        print repr(c)+' not in training columns, so removing it from test df'\n",
    "        test_df.drop([c], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print '\\nFor train_df:'\n",
    "    for column in train_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(train_df[column].isnull().sum())\n",
    "        print 'min: ',train_df[column].min()\n",
    "        print 'max: ',train_df[column].max()\n",
    "\n",
    "    print '\\nFor test_df:'\n",
    "    for column in test_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(test_df[column].isnull().sum())\n",
    "        print 'min: ',test_df[column].min()\n",
    "        print 'max: ',test_df[column].max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "X_train = train_df.drop(\"Survived\",axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_XXX</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId     Age  SibSp  Parch      Fare  Cabin_A  Cabin_B  Cabin_C  \\\n",
       "0            1  0.2750  0.125    0.0  0.014151      0.0      0.0      0.0   \n",
       "1            2  0.4750  0.125    0.0  0.139136      0.0      0.0      1.0   \n",
       "2            3  0.3250  0.000    0.0  0.015469      0.0      0.0      0.0   \n",
       "3            4  0.4375  0.125    0.0  0.103644      0.0      0.0      1.0   \n",
       "4            5  0.4375  0.000    0.0  0.015713      0.0      0.0      0.0   \n",
       "\n",
       "   Cabin_D  Cabin_E ...   Ticket_XXX  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0      0.0      0.0 ...          0.0           0.0         0.0       1.0   \n",
       "1      0.0      0.0 ...          0.0           0.0         0.0       0.0   \n",
       "2      0.0      0.0 ...          0.0           0.0         1.0       0.0   \n",
       "3      0.0      0.0 ...          1.0           0.0         0.0       0.0   \n",
       "4      0.0      0.0 ...          1.0           0.0         0.0       1.0   \n",
       "\n",
       "   Title_Mrs  Title_Officer  Title_Royalty    C    Q    S  \n",
       "0        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "1        1.0            0.0            0.0  1.0  0.0  0.0  \n",
       "2        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "3        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "4        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_XXX</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId       Age  SibSp     Parch      Fare  Cabin_A  Cabin_B  \\\n",
       "0          892  0.453947  0.000  0.000000  0.015282      0.0      0.0   \n",
       "1          893  0.618421  0.125  0.000000  0.013663      0.0      0.0   \n",
       "2          894  0.815789  0.000  0.000000  0.018909      0.0      0.0   \n",
       "3          895  0.355263  0.000  0.000000  0.016908      0.0      0.0   \n",
       "4          896  0.289474  0.125  0.111111  0.023984      0.0      0.0   \n",
       "\n",
       "   Cabin_C  Cabin_D  Cabin_E ...   Ticket_XXX  Title_Master  Title_Miss  \\\n",
       "0      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "1      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "2      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "3      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "4      0.0      0.0      0.0 ...          1.0           0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Officer  Title_Royalty    C    Q    S  \n",
       "0       1.0        0.0            0.0            0.0  0.0  1.0  0.0  \n",
       "1       0.0        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "2       1.0        0.0            0.0            0.0  0.0  1.0  0.0  \n",
       "3       1.0        0.0            0.0            0.0  0.0  0.0  1.0  \n",
       "4       0.0        1.0            0.0            0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmede/miniconda2/envs/ExoSOFTcondaEnv/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.122865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.121513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.106058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.105899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Male</td>\n",
       "      <td>0.084167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Female</td>\n",
       "      <td>0.066380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Class_3</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.030543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_U</td>\n",
       "      <td>0.028114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LargeFamily</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>0.020842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.020705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SmallFamily</td>\n",
       "      <td>0.017446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.016082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.013303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>0.013052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ticket_XXX</td>\n",
       "      <td>0.013029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Singleton</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>S</td>\n",
       "      <td>0.011211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>C</td>\n",
       "      <td>0.010832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Child</td>\n",
       "      <td>0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.009156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_E</td>\n",
       "      <td>0.009036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.007644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_B</td>\n",
       "      <td>0.006546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ticket_PC</td>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_D</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_C</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ticket_STONO</td>\n",
       "      <td>0.005861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Title_Officer</td>\n",
       "      <td>0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ticket_CA</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket_A5</td>\n",
       "      <td>0.003732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ticket_WC</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_A</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ticket_SOTONOQ</td>\n",
       "      <td>0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket_C</td>\n",
       "      <td>0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ticket_SOPP</td>\n",
       "      <td>0.001899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ticket_STONO2</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_F</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_G</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Title_Royalty</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ticket_PP</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ticket_FC</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket_A4</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ticket_SCPARIS</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ticket_SOC</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ticket_WEP</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ticket_FCC</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ticket_SCParis</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ticket_SCAH</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ticket_SC</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ticket_SOTONO2</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ticket_SCA4</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "0      PassengerId    0.122865\n",
       "1              Age    0.121513\n",
       "4             Fare    0.106058\n",
       "47        Title_Mr    0.105899\n",
       "19            Male    0.084167\n",
       "18          Female    0.066380\n",
       "22         Class_3    0.040254\n",
       "46      Title_Miss    0.030543\n",
       "12         Cabin_U    0.028114\n",
       "48       Title_Mrs    0.024390\n",
       "16     LargeFamily    0.021550\n",
       "20         Class_1    0.020842\n",
       "13      FamilySize    0.020705\n",
       "15     SmallFamily    0.017446\n",
       "2            SibSp    0.016082\n",
       "3            Parch    0.013303\n",
       "21         Class_2    0.013052\n",
       "44      Ticket_XXX    0.013029\n",
       "14       Singleton    0.011667\n",
       "53               S    0.011211\n",
       "51               C    0.010832\n",
       "17           Child    0.009584\n",
       "45    Title_Master    0.009156\n",
       "9          Cabin_E    0.009036\n",
       "52               Q    0.007644\n",
       "6          Cabin_B    0.006546\n",
       "29       Ticket_PC    0.006393\n",
       "8          Cabin_D    0.006221\n",
       "7          Cabin_C    0.006191\n",
       "40    Ticket_STONO    0.005861\n",
       "49   Title_Officer    0.004430\n",
       "26       Ticket_CA    0.004087\n",
       "24       Ticket_A5    0.003732\n",
       "42       Ticket_WC    0.003055\n",
       "5          Cabin_A    0.002696\n",
       "39  Ticket_SOTONOQ    0.002170\n",
       "25        Ticket_C    0.002040\n",
       "37     Ticket_SOPP    0.001899\n",
       "41   Ticket_STONO2    0.001630\n",
       "10         Cabin_F    0.001457\n",
       "11         Cabin_G    0.001418\n",
       "50   Title_Royalty    0.000639\n",
       "30       Ticket_PP    0.000612\n",
       "27       Ticket_FC    0.000604\n",
       "23       Ticket_A4    0.000470\n",
       "34  Ticket_SCPARIS    0.000446\n",
       "36      Ticket_SOC    0.000437\n",
       "43      Ticket_WEP    0.000417\n",
       "28      Ticket_FCC    0.000383\n",
       "35  Ticket_SCParis    0.000380\n",
       "33     Ticket_SCAH    0.000204\n",
       "31       Ticket_SC    0.000101\n",
       "38  Ticket_SOTONO2    0.000083\n",
       "32     Ticket_SCA4    0.000076"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = X_train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort(['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select top features for use in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 13)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_train_new = model.transform(X_train)\n",
    "X_train_new.shape\n",
    "\n",
    "X_test_new = model.transform(X_test)\n",
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.82603815937149272)\n",
      "('cv score ', 0.81929633412779468)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test_new)\n",
    "\n",
    "print('standard score ', logreg.score(X_train_new, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(logreg, X_train_new, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.8709315375982043)\n",
      "('cv score ', 0.66461128135285441)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred = svc.predict(X_test_new)\n",
    "\n",
    "#svc.score(X_train, Y_train)\n",
    "print('standard score ', svc.score(X_train_new, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(svc, X_train_new, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.99102132435465773)\n",
      "('cv score ', 0.79693649982975823)\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test_new)\n",
    "\n",
    "print('standard score ', random_forest.score(X_train_new, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(random_forest, X_train_new, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771061173533\n"
     ]
    }
   ],
   "source": [
    "# From Comment by 'Ewald' at:\n",
    "# https://www.kaggle.com/c/job-salary-prediction/forums/t/4000/how-to-add-crossvalidation-to-scikit-randomforestregressor\n",
    "if True:\n",
    "    num_folds = 10\n",
    "    num_instances = len(X_train_new)\n",
    "    seed = 7\n",
    "    num_trees = 500\n",
    "    max_features = 'auto'\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features,\n",
    "    min_samples_leaf=50)\n",
    "    results= cross_validation.cross_val_score(model, X_train_new, Y_train, cv=kfold, n_jobs=-1)\n",
    "    print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.81705948372615034)\n",
      "('cv score ', 0.6635015889229372)\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors \n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred = knn.predict(X_test_new)\n",
    "\n",
    "#knn.score(X_train_new, Y_train)\n",
    "\n",
    "print('standard score ', knn.score(X_train_new, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(knn, X_train_new, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.78002244668911336)\n",
      "('cv score ', 0.76240608330495974)\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "gaussian.fit(X_train_new, Y_train)\n",
    "\n",
    "Y_pred = gaussian.predict(X_test_new)\n",
    "\n",
    "#gaussian.score(X_train, Y_train)\n",
    "print('standard score ', gaussian.score(X_train_new, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(gaussian, X_train_new, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.019752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family</td>\n",
       "      <td>-0.126066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child</td>\n",
       "      <td>1.738955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.753647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>2.009490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>1.140570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>-0.099242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q</td>\n",
       "      <td>-0.280429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.786615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficient Estimate\n",
       "0      Age             -0.019752\n",
       "1     Fare              0.000800\n",
       "2   Family             -0.126066\n",
       "3    Child              1.738955\n",
       "4   Female              2.753647\n",
       "5  Class_1              2.009490\n",
       "6  Class_2              1.140570\n",
       "7        C             -0.099242\n",
       "8        Q             -0.280429\n",
       "9        S             -0.786615"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n",
    "# XGBoost stuff \n",
    "\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\": test_df[\"PassengerId\"],\n",
    "            \"Survived\": Y_pred\n",
    "        })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    ### Using XGboost\n",
    "    #X_train = train_df.drop(\"Survived\",axis=1)\n",
    "    train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "    train_y = train_df[\"Survived\"]\n",
    "    test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "    model = xgb.XGBClassifier(max_depth=10, n_estimators=300, learning_rate=0.05)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    # plot feature importance\n",
    "    plot_importance(model)\n",
    "    plt.show()\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33, random_state=7)\n",
    "    #accuracy = accuracy_score(y_test, predictions)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 80.34%\n",
      "Iteration: 1\n",
      "Accuracy: 73.90%\n",
      "Iteration: 2\n",
      "Accuracy: 77.63%\n",
      "Iteration: 3\n",
      "Accuracy: 80.00%\n",
      "Iteration: 4\n",
      "Accuracy: 81.36%\n",
      "Iteration: 5\n",
      "Accuracy: 78.64%\n",
      "Iteration: 6\n",
      "Accuracy: 80.00%\n",
      "Iteration: 7\n",
      "Accuracy: 77.63%\n",
      "Iteration: 8\n",
      "Accuracy: 80.68%\n",
      "Iteration: 9\n",
      "Accuracy: 81.36%\n"
     ]
    }
   ],
   "source": [
    "# basic try at iterative training with XGboost\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "# fit model on all training data\n",
    "acc = []\n",
    "mx_v = 0\n",
    "mx_e = 0\n",
    "ests = range(10,500,10)\n",
    "if False:\n",
    "    for est in ests:\n",
    "        #print est\n",
    "        model = xgb.XGBClassifier(max_depth=5, n_estimators=ests, learning_rate=0.05)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy *= 100.0\n",
    "        acc.append(accuracy)\n",
    "        #print(\"Accuracy: %.2f%%\" % (accuracy))\n",
    "        if acc[-1]>mx_v:\n",
    "            mx_v = acc[-1]\n",
    "            mx_e = est\n",
    "    print(\"maxes were: \",(mx_e,mx_v))\n",
    "\n",
    "    fig = plt.figure(figsize=(7,5))     \n",
    "    subPlot = fig.add_subplot(111)\n",
    "    subPlot.plot(ests,acc,linewidth=3)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.05)\n",
    "for i in range(10):\n",
    "    print \"Iteration: \"+str(i)\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.61%\n",
      "('It took: ', 5.418628931045532)\n"
     ]
    }
   ],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = train_X\n",
    "Y = train_y\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "if False:\n",
    "    thresholds = sort(model.feature_importances_)\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It took: ', 0.002824068069458008)\n"
     ]
    }
   ],
   "source": [
    "cv_params = {'max_depth': [3], 'min_child_weight': [1]}\n",
    "ind_params = {'learning_rate': 0.05, 'n_estimators': 100, 'nthread':100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), cv_params, \n",
    "                             scoring = 'accuracy', cv = 2, n_jobs = -1) \n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "\n",
    "#optimized_GBM.fit(train_X, train_y)\n",
    "\n",
    "#optimized_GBM.grid_scores_\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
