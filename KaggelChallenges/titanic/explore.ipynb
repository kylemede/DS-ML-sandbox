{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My playing with the Kaggle titanic challenge.\n",
    "\n",
    "I COPPIED THE INITIAL CODE and got lots of the ideas for this first Kaggle advanture from [here](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic/comments).\n",
    "\n",
    "I will later compact the important stuff from here into a kernal on my Kaggle account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\",dtype={\"Age\":np.float64},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many ages\n",
    "train_df['Age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many ages are NaN?\n",
    "train_df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age =  29.6792717087\n"
     ]
    }
   ],
   "source": [
    "# plot ages of training data set, with NaN's removed\n",
    "if False:\n",
    "    train_df['Age'].dropna().astype(int).hist(bins=70)\n",
    "print 'Mean age = ',train_df['Age'].dropna().astype(int).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see where they got on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x=\"Embarked\",data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x='Survived',hue='Embarked',data=train_df,order=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so clearly there were more people who got on at S, and it seems their survival is disproportional.  Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    embark_survive_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "    sns.barplot(x='Embarked', y='Survived', data=embark_survive_perc,order=['S','C','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting, actually those from C had higher rate of survival.  So, knowing more people from your home town didn't help.\n",
    "\n",
    "## Next, did how much they paid have an effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_df['Fare'].astype(int).plot(kind='hist',bins=100, xlim=(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get fare for survived & didn't survive passengers \n",
    "if False:\n",
    "    fare_not_survived = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 0]\n",
    "    fare_survived     = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 1]\n",
    "\n",
    "    # get average and std for fare of survived/not survived passengers\n",
    "    avgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "    std_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "    avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
    "    avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before digging into how the ages factor in, let's take the advice of others and replace NaN's with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  80.0\n",
      "min:  0.42\n",
      "After this gaussian replacment, there are:  0\n",
      "max:  80.0\n",
      "min:  0.42\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = train_df['Age'].min(), train_df['Age'].max()\n",
    "mu, sigma = train_df[\"Age\"].mean(), train_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = train_df.shape[0]\n",
    "\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(train_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = train_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "train_df['Age'] = rands\n",
    "\n",
    "\"\"\"\n",
    "## we will make a new column with Nan's replaced, then push that into the original df\n",
    "n = train_df.shape[0] # number of rows\n",
    "#randy = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = n)\n",
    "# draw from a gaussian instead of simple uniform\n",
    "# note this uses a 'standard gauss' and that tneeds to have its var and mean shifted\n",
    "randy = np.random.randn(n)*std_age_train + average_age_train\n",
    "idx = np.isfinite(train_df['Age']) # gives a boolean index for the NaNs in the df's column\n",
    "randy[idx.values] = train_df[idx]['Age'].values  ## idexing the values of randy with this\n",
    "#now have updated column, next push into original df\n",
    "train_df['Age'] = randy\n",
    "\"\"\"\n",
    "\n",
    "print 'After this gaussian replacment, there are: ',train_df['Age'].isnull().sum()\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot new Age Values\n",
    "if False:\n",
    "    train_df['Age'].hist(bins=70)\n",
    "# Compare this to that from a few cells up for the raw ages with the NaN's dropped.  Not much different actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets perform the same NaN replacement for the 'Age' with the test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## let's pull in the test data\n",
    "test_df = pd.read_csv(\"test.csv\",dtype={\"Age\":np.float64},)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  76.0\n",
      "min:  0.17\n"
     ]
    }
   ],
   "source": [
    "#### Do the same for the test data\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = test_df['Age'].min(), test_df['Age'].max()\n",
    "mu, sigma = test_df[\"Age\"].mean(), test_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = test_df.shape[0]\n",
    "\n",
    "print 'max: ',test_df['Age'].max()\n",
    "print 'min: ',test_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(test_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = test_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "test_df['Age'] = rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df['Age'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's make a couple nice plots of survival vs age\n",
    "# peaks for survived/not survived passengers by their age\n",
    "if False:\n",
    "    facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\n",
    "    #facet.map(sns.kdeplot,'Age',shade= True) # This keeps crashing the kernal, but I don't know why!!!!!!!!!!\n",
    "    facet.set(xlim=(0, train_df['Age'].astype(int).max()))\n",
    "    facet.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average survived passengers by age\n",
    "if False:\n",
    "    fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "    average_age = train_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "    sns.barplot(x='Age', y='Survived', data=average_age)\n",
    "    print 'max: ',train_df['Age'].astype(int).max()\n",
    "    print 'min: ',train_df['Age'].astype(int).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
    "train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "test_df.drop(\"Cabin\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmede/miniconda2/envs/ExoSOFTcondaEnv/lib/python2.7/site-packages/pandas/core/indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Family\n",
    "\n",
    "# Instead of having two columns Parch & SibSp, \n",
    "# we can have only one column represent if the passenger had any family member aboard or not,\n",
    "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
    "train_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\n",
    "train_df['Family'].loc[train_df['Family'] > 0] = 1\n",
    "train_df['Family'].loc[train_df['Family'] == 0] = 0\n",
    "\n",
    "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
    "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
    "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
    "\n",
    "# drop Parch & SibSp\n",
    "train_df = train_df.drop(['SibSp','Parch'], axis=1)\n",
    "test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
    "\n",
    "# plot\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Family',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Family', data=train_df, order=[1,0], ax=axis1)\n",
    "\n",
    "    # average of survived for those who had/didn't have any family member\n",
    "    family_perc = train_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\n",
    "    sns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n",
    "\n",
    "    axis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "\n",
    "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as males, females, and child\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "train_df['Person'] = train_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# No need to use Sex column since we created Person column\n",
    "train_df.drop(['Sex'],axis=1,inplace=True)\n",
    "test_df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(train_df['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(person_dummies_titanic)\n",
    "test_df    = test_df.join(person_dummies_test)\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Person',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Person', data=train_df, ax=axis1)\n",
    "\n",
    "    # average of survived for each Person(male, female, or child)\n",
    "    person_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
    "    sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
    "\n",
    "train_df.drop(['Person'],axis=1,inplace=True)\n",
    "test_df.drop(['Person'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not surprising, woman and children had higher survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pclass\n",
    "\n",
    "# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\n",
    "if False:\n",
    "    sns.factorplot('Pclass','Survived',order=[1,2,3], data=train_df,size=5)\n",
    "\n",
    "# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n",
    "pclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train_df = train_df.join(pclass_dummies_titanic)\n",
    "test_df    = test_df.join(pclass_dummies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also unsurprising.  The higher the booking class, then higher the chances to survive.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Now lets get to actually training and building a model to make predictions with!\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problems with the raw data\n",
    "- a couple NaNs in 'Embarked', so drop column\n",
    "- 'Name' strings can't be converted to anything useful, so drop column\n",
    "- replace NaNs in 'Fare' with median\n",
    "- 'Ticket' can't be converted to anything useful, so drop column\n",
    "- 'PassengerID' has no importance, so drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "# only for test_df, since there is a missing \"Fare\" values\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
    "train_df.drop(['Name'], axis=1,inplace=True)\n",
    "test_df.drop(['Name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Ticket'], axis=1,inplace=True)\n",
    "test_df.drop(['Ticket'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['PassengerId'], axis=1,inplace=True)\n",
    "#test_df.drop(['PassengerId'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "# Either to consider Embarked column in predictions,\n",
    "# and remove \"S\" dummy variable, \n",
    "# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n",
    "\n",
    "# OR, don't create dummy variables for Embarked column, just drop it, \n",
    "# because logically, Embarked doesn't seem to be useful in prediction.\n",
    "\n",
    "embark_dummies_train  = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_train.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n",
    "#embark_dummies_test.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(embark_dummies_train)\n",
    "test_df    = test_df.join(embark_dummies_test)\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The names are also pointless, so drop them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Family  Child  Female  Class_1  Class_2  C  Q  S\n",
       "0         0  22.0   7.2500       1      0       0        0        0  0  0  1\n",
       "1         1  38.0  71.2833       1      0       1        1        0  1  0  0\n",
       "2         1  26.0   7.9250       0      0       1        0        0  0  0  1\n",
       "3         1  35.0  53.1000       1      0       1        1        0  0  0  1\n",
       "4         0  35.0   8.0500       0      0       0        0        0  0  0  1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age     Fare  Family  Child  Female  Class_1  Class_2  C  Q  \\\n",
       "0          892  34.5   7.8292       0      0       0        0        0  0  1   \n",
       "1          893  47.0   7.0000       1      0       1        0        0  0  0   \n",
       "2          894  62.0   9.6875       0      0       0        0        1  0  1   \n",
       "3          895  27.0   8.6625       0      0       0        0        0  0  0   \n",
       "4          896  22.0  12.2875       1      0       1        0        0  0  0   \n",
       "\n",
       "   S  \n",
       "0  0  \n",
       "1  1  \n",
       "2  0  \n",
       "3  1  \n",
       "4  1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print '\\nFor train_df:'\n",
    "    for column in train_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(train_df[column].isnull().sum())\n",
    "        print 'min: ',train_df[column].min()\n",
    "        print 'max: ',train_df[column].max()\n",
    "\n",
    "    print '\\nFor test_df:'\n",
    "    for column in test_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(test_df[column].isnull().sum())\n",
    "        print 'min: ',test_df[column].min()\n",
    "        print 'max: ',test_df[column].max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "X_train = train_df.drop(\"Survived\",axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.80808080808080807)\n",
      "('cv score ', 0.79688684598796955)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('standard score ', logreg.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(logreg, X_train, Y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.98765432098765427)\n",
      "('cv score ', 0.78238054704346838)\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print('standard score ', random_forest.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(random_forest, X_train, Y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family</td>\n",
       "      <td>-0.073713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child</td>\n",
       "      <td>1.393479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.668472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>1.909668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>1.092092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>-0.079618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q</td>\n",
       "      <td>-0.318296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.722187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficient Estimate\n",
       "0      Age             -0.019708\n",
       "1     Fare              0.000834\n",
       "2   Family             -0.073713\n",
       "3    Child              1.393479\n",
       "4   Female              2.668472\n",
       "5  Class_1              1.909668\n",
       "6  Class_2              1.092092\n",
       "7        C             -0.079618\n",
       "8        Q             -0.318296\n",
       "9        S             -0.722187"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\": test_df[\"PassengerId\"],\n",
    "            \"Survived\": Y_pred\n",
    "        })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEZCAYAAAB2AoVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X98lXX9//HH2eb4/WP4AfdhIOhwrzQSbYQgCGWDMM3E\nHyFgJWGCiPkDFZARoBmgImSijkj8SAUf0PqiZplUahKRDMOG+KIkMMcnUX5uzmLA+f5xHeaADc7m\nzna263m/3bhxznWu6329XhOf5zrXrnO9I9FoFBERadpSGroAERFJPIW9iEgIKOxFREJAYS8iEgIK\nexGREFDYi4iEQFpDFyDhYGaHgL8Ch2KLosA6d7++luP1Bsa4+w11VOLR438F+KK735KI8Y+z3+7A\nA+5+ZX3uV5o+hb3UlyjweXffXUfj9QSy6misY7j7s8CziRr/OLoDOQ2wX2niIvpSldSH2JH9f7n7\nripe+xTwA6ADkAr80N0Xm1kEmAecB7QBIsB1wD+B1UBb4OfAk8DD7v6Z2HiDDj83s+lAP6Az8Bd3\n/4aZ3QVcTnAacysw3t3/dVRN3wSudPevmNnvgULgQqAj8BBwCjAIaAl8zd03xtZ7E+gNnAz8xN1n\nxMa7DPhurIcSYKK7v1apvv8GioA+sVpfcfeLYrVeCjQHWgG3u/vK2HbdY9t1A3YAw939X2Z2BlAA\ndAIOAve6+3Iz6ww8DHQFTgKWufvsOP7zSROgc/ZSn35vZuvN7PXY3/9lZqnAU8Akd/8c8HngdjPr\nQxDy/+3u/dy9J0GoT3b3dwmC8w/uPiY29tFHLZWfnwr0igX914HPAH3c/bPAr4AfV1Nv5TG6xda/\nApgD/C5W7wvATUftqx+QCww3sy+bmQGPAsPc/VxgOrDSzFpX2uYcdx9F8Gb2dizoTyV4gxnk7ucA\n+cDdlfY1ALjC3c8E9gBjY8uXAf8b+5ldDNwb29cS4Mexus8DBpuZTheFhE7jSH065jSOmZ0JZAOP\nx47kITiKPdfdC8xsmpmNi63zeWBfLfb7J3c/HNyXAJ8DCoMMJgVoEccYP4/9/TbBm8ALlZ4PqrRe\ngbsfAvaa2QrgS8BbwCp33wbg7r83s/cI3hCOrq+Cu78T+4RxjZn1APoCrSut8pK7fxh7/DrQwcwy\ngF7E3sBib4xnmFnLWJ0ZZva92DatgHMI3myliVPYS32KVLEsFdgTO2oGwMw6AXvM7GJgPvAA8P8I\nQnNUFWNEjxo7/ajXS4/a3xx3L4jt6ySC00cn8p/KT9z9YDXrHaj0OIXgNEpVn6BTCU6lHF1fBTP7\nLEHfDxK8ubwMPFJplY8qPT78MzgQe1zx5mFmOcDh01T93P0/seUnHzWGNGE6jSMNzYGPzGwUgJl1\nJTh3nQvkAc/EgrkQuIwgJCEItcNh+T5wauy0UCS2XnVeAK4zszax598jOD1UE1W9aR12jZlFYkfY\nXwOeAX4HDIldaYOZXQh0AdZWsX3lvi4AXnP3+cArwDA+7r9K7l5C8LP6ZmxfXYFXCT4t/Qm4Pba8\nPcHvPb56gl6liVDYS32p8koAdy8nCJzrzGwD8GtgqruvAR4DvmBmfyEIpr8Dp8U2/RPwKTN72t03\nAQsJQu6PwPbj1LEIeA74k5n9leCqnmtrWPvxrmpoAfw5VsfD7v5SrL7xwC/M7A3g+8AlsWA+2ptA\n1Mz+BPwM6GhmG4F1BKewOphZqxPUO4rg9wV/AVYSXKK6I7a8b6yGNcBP3X3pCcaSJkJX44jUkdjV\nOD9095+fcGWReqYje5G6oyMnSVo6shcRCQEd2YuIhIDCXkQkBJL2OvvCwkKdXxIRqYXc3NxjLg9O\n2rAHyM3NPfFKTURhYWFo+g1Tr6B+m7pk67ewsLDK5TqNIyISAgp7EZEQUNiLiISAwl5EJAQU9iIi\nIaCwFxEJAYW9iEgIKOxFREJAYS8iEgIKexGREFDYi4iEgMJeRCQEFPYiIiGgsBcRCQGFvYhICCjs\nRURCIGGTl5hZKvAi0B7YBaQD+4BvuvvORO1XRCRZDBs2jDZt2gDQpUsXhg8fzr333ktaWhrnn38+\nEyZM4MCBA0yaNIni4mLS0tK45557OO200yrGePbZZ/npT3/KsmXLPlEtiZypKgtoCzwJtHX3u81s\nODANuCWeATZv3pzA8pLLtm3bKv5RNHVh6hXUb1NXVb/Z2dkcPHiQSCTCk08+WbH8sssu4+GHH6ZL\nly5cf/31bNq0ie3bt3Po0CGWLVvGH//4R+bNm8dDDz0EwKZNm3j66afrpM5Ehv2jQA/gK8CU2LJf\nEYR9XMbOXpWAspLYc/9q6ArqT5h6BfXb1FXqt2zvDpbMGsm///1vysrKGDNmDAcPHmTChAmUl5fT\npUsXAAYMGMCaNWsYNGgQBw4cIBqNUlJSwkknnQTA7t27efDBB5k6dSrTpsUdm9VKZNiPB5YBB4G9\nsWUlBEf7cWmdkZWAskREEq958+aMGTOGq666iq1bt/Ltb3+btm0/jr9WrVrx7rvv0qpVK4qLixk6\ndCh79uyhoKCAQ4cOkZ+fz5QpU0hPTycajX7ieupjwvF9wOHPOG2APfWwTxGRBlNUVERWVhZdunSp\nmAA8JSWFHTt2VDx/6623OHjwIHPmzKFHjx4MHz6cXbt2cfPNN3P99dfj7kycOJH9+/ezfft2brnl\nFr7+9a/Xuqb6CPvVwMXAOuDLwB/i3bB0d3GiahIRSYiyvTvo2TOPwsJCNm/ezPTp03nvvfdISUmh\nffv2dOrUiS5dulBQUMCECRNYvXo1aWlp5ObmUlZWRlpaGldccQWjRo0CoLi4mIkTJzJ//vy49n/4\nzeRoiQ77KMG5+yfN7A/Af4CR8W5cMDkvUXUlnaKiInr27NnQZdSLMPUK6repq6rf7OxsTjvtNKZM\nmcLIkSNJSUlh1qxZpKSkcPvtt3Po0CH69+/P2WefTY8ePbjrrrsYNWoUBw4cYOLEiTRv3rzO64zU\nxbmgRCgsLIzm5uY2dBn1prCwkLD0G6ZeQf02dcnWb6yeyNHL9aUqEZEQUNiLiISAwl5EJAQU9iIi\nIaCwFxEJAYW9iEgIKOxFREJAYS8iEgIKexGREFDYi4iEgMJeRCQEFPYiIiGgsBcRCQGFvYhICCTs\nfvZmlgqsAk4CLgG+AFzp7qMStU8RkXjs3LmTK664gsWLF9OuXTvy8/MpKSmpmDmqa9euAESjUa6/\n/nry8vIYPnw4hw4dYtasWWzcuJH9+/dz00030bp16wbuJj6JnLwkC2jt7p8zs/nAEOAvNRlg8+bN\nCSksGVU1Q31TFaZeQf0mk+zsbKLRKNOnT6+YIOT+++/n0ksvZejQoaxdu5YtW7ZUhP38+fPZt29f\nxfYrV67k4MGD/OxnP+O9997jhRde4NOf/nSD9FJTiQz7R4EzzOxR4HfAL4CxNRlg7OxViagreVWa\nob7JC1OvoH6TQNneHSyZNZIVK1YwYsQICgoKAFi/fj1mxujRo+nSpQtTp04F4IUXXiAlJYULLrig\nYoxXX32VnJwcxo4Noiw/P58dO3bUfzO1kMiwHw8sdfcbAMxsUE0HaJ2RVedFiUh4rVq1ipNPPpn+\n/fvz2GOPEY1GKS4upn379ixevJgFCxawcOFCLrroIp577jkeeughFixYULH97t272bZtGwUFBbz2\n2mtMmTKFW2+9tQE7il99TDguIpIUnnnmGVq0aMELL7zAtm3bmDBhApFIhIyMDAoLC8nMzGT58uW8\n8847bNmyhcsvv5z333+ftLQ0ysrKOHToEKeeeiqFhYWkpKTwt7/9Dah+ku9kkuiwP2YexJoo3V1c\nV3WISMiV7d1BwUMPkZOTA8A3vvENZs6cyfz589mzZw+DBg1i48aN9O7dmzvuuKNiu4cffpiOHTsy\nfPhw0tPT2bRpE+PGjeOtt96iW7duAEk3B21VEh32n2g284LJeXVVR9Kraob6pipMvYL6TSbZ2dnH\nLJs0aRL5+fksW7aMNm3aMHfu3Gq3v+qqq5gxYwbDhw8HYObMmZSVlSWs3roUiUY/UR4nTGFhYTSZ\n3i0TLdlmqE+kMPUK6repS7Z+Y/Ucc1ZFX6oSEQkBhb2ISAgo7EVEQkBhLyISAgp7EZEQUNiLiISA\nwl5EJAQU9iIiIaCwFxEJAYW9iEgIKOxFREJAYS8iEgIKexGREFDYi4iEgMJeRCQEEjZ5iZmlAi8C\nzYDXgN5AOjDD3Z+PZ4zNmzfXaU3Z2dlEIhHy8/P5xz/+QUpKCjNnzqRDhw7k5+dTUlLCwYMHmTNn\nDl27duWJJ57g+eefJxKJMHDgQG688cY6rUdEpL4kcqaqLKAt8BDQx90HmFln4Mp4Bxg7e1WdFXN4\nZvl33nmHSCTC0qVL+fOf/8yDDz5Iu3btuPTSSxk6dChr165ly5YtADz33HM89dRTRKNRRo4cyeDB\ngyumNBMRaUwSGfaPAj2AbwKrzOy52PKb4h2gdUZWnReVl5fHhRdeCMD27dtp164d69evx8wYPXo0\nXbp0YerUqaSlpbFo0SIAIpEIBw4coFmzZnVej4hIfUjkOfvxwCbgANDD3S8B7gOeSOA+45KSksLk\nyZP53ve+xyWXXEJxcTHt27dn8eLFZGZmsnDhQtLS0mjfvj0Ac+bM4ayzzqqYXFhEpLFJ9ITjADuB\n5wDc/RUza7DzIEVFRZSUlADBxMFDhgzhzjvvpEWLFmRkZFBYWEhmZiYrVqygf//+lJeXU1BQQMuW\nLRk9enS1s7bXlUSPn0zC1Cuo36auMfRbH2H/KnAx8Asz6wVsi3fD0t3FdVZE2d4d9OyZx6ZNm3jv\nvfe4/vrrKS0tpXnz5vTu3Zs9e/YwaNAgNm7cSG5uLrm5uYwZM4b+/ftz3XXX1Vkd1Um2SYsTKUy9\ngvpt6pKt3+reeBId9lHgR8BjZrYmtmxcvBsXTM6r02Kys7Pp2rUrU6ZM4ZprruHAgQPk5+fzqU99\niqlTp7J06VLatm3L3LlzWbVqFevWraO8vJyXX36ZSCTCxIkT6dWrV53WJCJSHxIW9u6+DTg/9nRM\nbcZIxJUvLVq0YP78+ccsf/zxx494npeXx4YNG+p8/yIiDUFfqhIRCQGFvYhICCjsRURCQGEvIhIC\nCnsRkRBQ2IuIhIDCXkQkBBT2IiIhoLAXEQkBhb2ISAgo7EVEQkBhLyISAgp7EZEQUNiLiIRAwm5x\nbGapwItAM6AX8OfYS2vcfWqi9nvYgQMHuOuuuyguLqa8vJxx48ZxzjnnkJ+fT0lJCQcPHmTOnDl0\n7doVgF27djFixAieffZZ0tPTE12eiEi9SuTkJVlAG+Bq4EF3/2pNB9i8eXOtdpydnc0zzzxDRkYG\n9913H3v27GHYsGH07duXSy+9lKFDh7J27Vq2bNlC165defXVV5k7dy47d+6s1f5ERJJdIsP+UeAM\ngqP7XWb2O6AMuM3d40rxsbNX1XinZXt3sGTWSC666CKGDh0KQDQaJTU1lfXr12NmjB49mi5dujB1\navABIzU1lSeeeILLL7+8xvsTEWkMEnnOfjzwJvANYJa7XwjMAn4S7wCtM7Jq/Kdlu05AMCNVy5Yt\nKS0t5eabb+bWW2+luLiY9u3bs3jxYjIzM1m4cCEA/fr1o127dkSj0Tr/IYiIJIP6mHB8HXAQwN1X\nm1nnRO+wqKiIkpISdu7cybx58xgyZAiZmZm0atWKjIwMCgsLyczMZMWKFfTv379iu/379/P666+T\nllYfP5ZjNYYZ6utKmHoF9dvUNYZ+E51qEWA6sAu438x6Ae/Eu3Hp7uIa77Bs7w569syjQ4cOTJs2\njenTp9O3b18A+vbty969exk0aBAbN24kNzf3iFnh09PTOffccxvkF7TJNkN9IoWpV1C/TV2y9Vvd\nG0+iwz4KzAZ+amYXA+XAtfFuXDA5r1Y7zc7OZvbs2ezbt49HHnmEBQsWEIlEmDNnDlOnTmXp0qW0\nadOGuXPnHrFdJBKp1f5ERJJdwsLe3bcB58eeXlKbMXJycmq9/6lTp1b8Arayxx9/vNptfvvb39Z6\nfyIiySyusDezPsAA4GHgOeBcYJy7P53A2kREpI7EezXOQwS/aL2S4PLJzwKTE1WUiIjUrXjDPsXd\nXwEuBp52939SP1fyiIhIHYg37MvMbCLwReA5M/sOUJK4skREpC7FG/ajgFbAMHffTXArhJEJq0pE\nROpUXGHv7sXA74BeZpYO/NLd301oZSIiUmfiCnszuxm4B7iN4OZmBWZ2eyILExGRuhPvaZxrgS8B\nH7r7TuBzwLcSVZSIiNSteMP+oLvvr/T838TudyMiIskv3rB/2cweAFqZ2WXAM4C+bioi0kjEG/Z3\nAH8DNhDcsvh5QOfsRUQaiXi/GPUrd/8SUJDIYkREJDHiPbJvaWZdE1qJiIgkTLxH9h2BrWa2A/iI\n4D71UXc/PWGViYhInYk37L9U04HNLJVg/tlTgG0E1+d/AHzb3T+o6Xg1ceDAAe666y6Ki4spLy9n\n3LhxZGZmMm7cOLp37w7AiBEjuOiii5g3bx5r1qwhJSWF2267jT59+iSyNBGRBhFv2A+qZvmTx9km\nC2gL/BLY5e6zzeyLBPPQfjuenW7eHNe85Md44403yMjI4L777mPPnj0MGzaMG2+8kW9961tce+21\nFett2rSJN954g+XLl1NcXMz48eNZuXJlrfYpIpLM4g37L1R6fBJwAfAKxw/7R4EewF6Cb94CrCa4\nJ35cxs5eFe+qFcr27uBH0y/ny1/+MgDRaJS0tDQ2btzIli1bWLVqFd26dWPq1KmceeaZ/PjHPwag\nuLiYtm3b1nh/IiKNQVxh7+6jKz83sw7A/55gs/HAMmAN8FWCyza/CrSIt7jWGVnxrnqE5s2b07Jl\nS0pLS7n55pu55ZZb2L9/P1dddRVnnXUWjz32GD/84Q+ZNGkSKSkpzJs3j5/85CdMmzatVvsTEUl2\ntb0nfSnQPY71ogSnbX5oZi8RnNL5Zy33GbeioiK2bt3KvHnzGDJkCJmZmZSVlfHRRx9RWFhI586d\nefHFFysm5h04cCB9+vThu9/9Ls2aNaNTp06JLrFKjWGG+roSpl5B/TZ1jaHfeKcl/D1BcENwJc7p\nBF+sOpEIMBD4kbuvMbPLCU7lxKV0d3G8q1Yo27uDrKxcZs6cyfTp0+nbty8AX/va15g2bRqf+cxn\n2LRpE/369aO8vJzf/OY3fPe736W8vJy2bdty9tlnk5VVu08Un0SyzVCfSGHqFdRvU5ds/Vb3xhPv\nkf2MSo+jwAfu/mYc20UBB5aYGcC7wJg490nB5Lx4Vz3C8uXL2bdvH4888ggLFiwgEokwZcoU7r33\nXtLT0+nYsSN33303LVq04Ne//jUjRowgGo0ycuTIBgl6EZFEizfsr3T3myovMLP/cfdvVreBu28D\nzo897V+b4nJycmqzGfn5+eTn5x+zfNmyZccsmzFjRq32ISLSmBw37M1sEcEpm95m9ulKL50EtEtk\nYSIiUndOdGT/PYJfxP4AmFlp+QFgU4JqEhGROnbcsHf3rcBWgukIOxDMQxsBUoFzCKYqFBGRJBfv\n1TjfB24kOH2zE+gMrAPOS1xpIiJSV+K96+VIoCvBF6k+D+QB7yeoJhERqWPxhv12d98HFAG93P33\nBDc4ExGRRiDeSy/3mtnXgULgJjPbDmQkriwREalL8R7ZjwE6uftLBL+wLQCOvZBdRESSUrw3Qttu\nZo+Z2dkE89G2cPcPE1uaiIjUlbiO7GP3od8ArAQ6EcxaNSSRhYmISN2J9zTO94EBwB53/xfBZCb3\nJ6wqERGpU/GGfUos5AGI8yZoIiKSJOK9GuddM7sEiJpZe4IvWL2TuLJERKQuHffI3swO3+93LDCK\n4ItVbxPcKuH6xJYmIiJ15URH9s8Cn3X3HWa2zt1H1EdRIiJSt04U9pFKj0cBc+Md2MxSgVUE99O5\nGPhv4E8E1+vvj2eMzZs3x7s7ALp168a0adMoLi6mvLyccePGceGFFwIwa9YsTj/9dIYPHw7AwoUL\nef7552nTpg1jxozh85//fI32JSLSmJwo7KOVHkeqXatqWUBrd/+cmbUBHgD+XZMBxs5eFfe6ZXt3\n8M0vdiIjI4P77ruPPXv2MGzYMM4991zuvPNOtm3bxumnnw4EbyLPP/88K1asIBqNcvXVV9OvXz+a\nNWtWk/JERBqNmkw4Hj3xKkd4FDjDzB4D2gJTCK7Tj1vrjJpNEThgwAB69OgBQDQaJS0tjbKyMm66\n6SZeeeWVivXefvtt+vTpw0knnQQEnwjcnbPPPrtG+xMRaSxOdOnlp81si5ltqfzYzP4RW3Y84wkm\nONkO/NLd/0rNPx3USPPmzWnZsiWlpaXcfPPN3HrrrWRlZR0T4jk5Oaxbt46ysjJ2797N66+/TllZ\nWSJLExFpUCc6sq/dJLBHuobg0s3rgEzgNwS3Sa5zRUVFbN26lXnz5jFkyBBOOeWUipnWt2/fTllZ\nWcXz/v37c/XVV3PyySdz6qmn8n//93/VzspeXxp6//UpTL2C+m3qGkO/J5qpatsn3YG7V7xhmNk/\ngMHxblu6uzju/ZTt3UFWVi4zZ85k+vTp9O3b94jX16xZQ8eOHcnNzWXXrl0UFRXxzDPPUFpaypgx\nY7jsssuIRBL6weO4CgsLyc3NbbD916cw9Qrqt6lLtn6re+OpyTn72jj6PH+UGpzKKZicV6OdLV++\nnH379vHII4+wYMECIpEIixYtIj09/Yj1OnTowNtvv82VV15Jeno6d9xxR4MGvYhIoiUs7GOfCs4/\natnpNRkjJ6dmZ5Hy8/PJz6/6zssTJkw44vndd99do7FFRBqzeO+NIyIijZjCXkQkBBT2IiIhoLAX\nEQkBhb2ISAgo7EVEQkBhLyISAgp7EZEQUNiLiISAwl5EJAQU9iIiIaCwFxEJAYW9iEgIKOxFREIg\nYbc4NrNUYBVwAfBXYDeQAZzi7p0Tsc8NGzbwwAMPsGTJEjZt2sSMGTNIS0uje/fu3HvvvQA88cQT\nPP/880QiEQYOHMiNN96YiFJERJJKIicvyQJau3vFPszsWeCOeAfYvHlzXOtlZ2ezePFiVq5cSatW\nrQBYsGABEyZM4IILLuD222/npZdeIjs7m+eee46nnnqKaDTKyJEjGTx4cI3vmy8i0tgkMuwfBc4w\ns0fd/QYzuxzY5e6r4h1g7OwTr1q2dwdLZo2kW7duLFiwgDvvvBOAM888k927dxONRvnwww9JS0uj\nc+fOLFq0CIBIJMKBAwdo1qxZrZoTEWlMEhn244Gl7n5D7Plk4OqaDNA6IyvudQcPHkxx8cdz1nbv\n3p27776bxx57jDZt2tCnTx9SU1Np3749AHPmzOGss86iW7duNSlJRKRRSvQctACY2ZnAbnffkojx\ni4qKKCkp4f3336e0tJTCwkJmzJjBtGnTyMrK4sUXX+S2225j9OjRlJeXU1BQQMuWLRk9enRSzQqf\nTLUkWph6BfXb1DWGfusl7IE84Fc13ah0d/EJ1ynbu4OePfPIycmhuLiY1q1bk5ubS8eOHTnvvPM4\n5ZRT2L17Nx988AG5ubmMGTOG/v37c91119Wmj4RJthnqEylMvYL6beqSrd/q3njqK+wN+E1NNyqY\nnBfXetnZ2ccsu+eee7jllltIS0sjPT2de+65h1WrVrFu3TrKy8t5+eWXiUQiTJw4kV69etW0NBGR\nRiVhYe/u24DzY48n1GaMml4lk5WVxbJlywDIzc1l6dKlR7zeuXNnNmzYUJtSREQaNX2pSkQkBBT2\nIiIhoLAXEQkBhb2ISAgo7EVEQkBhLyISAgp7EZEQUNiLiISAwl5EJAQU9iIiIaCwFxEJAYW9iEgI\nKOxFREJAYS8iEgIJu8WxmaUCLwLtgXeBtsBJwER3/1Nd72/Dhg088MADLFmyhF27dpGfn09JSQkH\nDx5kzpw5dO3aFYBdu3YxYsQInn32WdLT0+u6DBGRpJTIyUuyCAJ+JcGUhA+ZWQ6wFIhrWpfNmzcf\n9/Xs7GxSU1NZtGgRK1eupFWrVgDcf//9XHrppQwdOpS1a9eyZcsWunbtyquvvsrcuXPZuXPnJ2pM\nRKSxSWTYPwr0ADKB2bFlJwEfxTvA2Nmrqn2tbO8OlswaSU5ODt26dWPBggXceeedAKxfvx4zY/To\n0XTp0oWpU6cCkJqayhNPPMHll19eu45ERBqpRJ6zHw+86e43uPt/zCwTWAJMjneA1hlZ1f5p2a5T\nxXqDBw8mNTW14nlxcTHt27dn8eLFZGZmsnDhQgD69etHu3btiEajddWjiEijUC9z0JrZZ4CfEZyv\nf7Wuxi0qKqKkpASA999/n9LSUgoLC2nVqhUZGRkUFhaSmZnJihUr6N+/f8V2+/fv5/XXXyctrb6m\n4I1PY5ihvq6EqVdQv01dY+g34WlnZmcCy4Gvuftfa7Jt6e7ial8r27uDnj3zKuapLS4upnXr1uTm\n5tK3b1/27t3LoEGD2LhxI7m5uUfM/p6ens65556bVL+gTbYZ6hMpTL2C+m3qkq3f6t546uPQ9vtA\nM+AHZhYB9rj7sHg2LJicd9zXs7Ozq1w+adIk8vPzWbp0KW3atGHu3LlHvB6JROLZvYhIk5GwsHf3\nbcD5n2SMw0ft8cjKymLZsmUAdO7cmccff7zadX/7299+krJERBodfalKRCQEFPYiIiGgsBcRCQGF\nvYhICCjsRURCQGEvIhICCnsRkRBQ2IuIhIDCXkQkBBT2IiIhoLAXEQkBhb2ISAgo7EVEQkBhLyIS\nAgp7EZEQSNj97M0sFXgRaA/8C2gF/Ae4xt13xDPG5s2bj1mWnZ1NamoqGzZs4IEHHmDJkiW88847\nTJ48mZSUFM444wymT58OwA033MDevXtJS0ujefPmFXPRioiETSJnqsoC2gKLgSx3n2xm1wF3ArfH\nM8DY2auOeF62dwdLZo3klVdeYeXKlbRq1QqAWbNmcdttt9G7d2+mT5/OqlWryMvL45133uGXv/xl\nnTYlItIYJfI0zqNAD2AC0Ca2rC2wP94BWmdkHfGnZbtOAHTr1o0FCxZUrLdx40Z69+4NwMCBA1mz\nZg07d+7YovqjAAAHgklEQVRk3759jBs3jlGjRvHSSy/VSVMiIo1RIo/sxwNLgbHAL8xsI5ABXPBJ\nBi0qKqJbt268+eablJaWUlhYyP79+ysm2S0uLmbr1q2sX7+eIUOGMHToUEpLS5k+fTozZsygbdu2\nn7SvhGkMM9TXlTD1Cuq3qWsM/SZ6wvEIMAOY4+4/MrPPAD8HetV2wJ49e5KTk0NxcTGtW7cmNzeX\nZs2aVczuvmfPHk477TQuvPBCBgwYQIsWLQBYuXIlbdu2TapZ4CtLthnqEylMvYL6beqSrd/q3njq\n42qcXcC+2OP3+fiUzgmV7i4+4k/Z3qp/r3vWWWfx2muvAfDKK6+Qm5vL6tWrueWWWwD48MMP+fvf\n/052dvYn6UNEpNFK9JF9FJgG/NjMxsf2d128GxdMzjtmWVWBPWnSJKZNm0Z5eTnZ2dkMHTqUSCTC\n6tWrGT58OCkpKdx22220b9++9p2IiDRiCQt7d98GnB97enFtxsjJyan2taysLJYtWwZA9+7dWbJk\nyTHrTJkypTa7FRFpcvSlKhGREFDYi4iEgMJeRCQEFPYiIiGgsBcRCQGFvYhICCjsRURCQGEvIhIC\nCnsRkRBQ2IuIhIDCXkQkBBT2IiIhoLAXEQkBhb2ISAgo7EVEQkBhLyISAgp7EZEQUNiLiIRAJBqN\nNnQNVSosLEzOwkREklxubm7k6GVJG/YiIlJ3dBpHRCQEFPYiIiGgsBcRCQGFvYhICCjsRURCIK2h\nC6jMzCLAI0Av4N/Ade6+pWGr+uTM7Dxgtrt/wcyygSeAQ0CRu98YW+e7wMVAOXCru79W3brJyszS\ngMeB7kA6cC/wJk233xTgR4AR1DwO+A9NtF8AM+sErAPygIM07V7XA3tiT/8BLAR+QNDXi+5+d3WZ\nZWZ9gfmV1633Bo6SbEf2lwHN3P18YArwYAPX84mZ2R0EgdAstuhB4C53HwSkmNlXzexcYKC7nweM\nABZUt249l19T1wAfuPtA4CLgYZp2v18Bou4+AJgGfJ8m3G/szfwxoCy2qCn32ozgv+2FsT9jCHq/\n2t0vAM4zs3OoPrMerWLdBpVsYT8A+DWAu68FejdsOXXi78CwSs9z3f0Psce/AgYT9P0bAHf/J5Bq\nZv9Vxbp59VNyrS0nCD0I/m0dAD7bVPt195XA9bGn3YDdNOF+gQcIQmw7EKFp99oLaGVmL5jZKjO7\nAEh3962x118g6OHozMo1szZVrPvF+iy+KskW9m2BvZWeH4h9VG603P0XBKF3WOVvtpUA7YA2HNn3\n4eWcYFlScfcyd/8w9o99BTCVJtwvgLsfMrMngIeAn9FE+zWza4Ed7v4iH/dY+f/NJtNrTBlwv7t/\nCbgBWMzHn2ig+n4Pxpbtq2LdBpVsQbqP4Ad1WIq7H2qoYhKkcj9tCI4G9xG80VVevqeKdfeQ5Mys\nK/A74H/cfRlNvF8Ad78WyAEWAS0qvdSU+h0NDDaz3xMc9T4JdKz0elPqFWAz8FMAd/8bQaB3qPR6\n5X6PyCyq/xk0qGQL+9XAlwFiv+D4a8OWkxDrzWxg7PFFwB+APwJDzCxiZqcSvMntBF6vYt2kZWan\nEHxkvdPd/ye2uKoemkq/15jZ5NjTfxMc1a0zs0GxZU2mX3cf5O5fcPcvAH8Bvg78qqn+twW+BcwF\nMLPOQEvgQzM7LfZL2S/xcb9HZJa7lwL/qWLdBpVUV+MAvyA4elgdez66IYtJkNuBH5nZScAm4Cl3\nj5rZH4A1BB+Rx1e3bkMUXANTgPbAtNgVGVHgZuCHTbTfnwOLzexlgv+XvgO8BSxqov0erSn/W/4x\nwX/bPxB8Khkd+/tnBAfJv4ldZbSOqjPrhqPXrdfqq6AboYmIhECyncYREZEEUNiLiISAwl5EJAQU\n9iIiIaCwFxEJAYW9iEgIJNt19iIJY2bdCL4ZuTG2KELwXYCvuHtxgxUmUg8U9hI2xe7+2YYuQqS+\nKexFjmJmI4E7CG5g9w/gGnffb2ZzCG5pWw4sdPeHzOwMgvucdwBKge+4e6GZLQZOBrKBO4H3gHkE\n9875ABjr7tvquTUJMZ2zl7DJMrP1ZvZ67O+JVaxzDzDY3T9HcPuDT5nZlUA/4NPAecC1sXsB/QSY\n7+69gNuAp2O3BIDg3v6fJrjl7yJghLv3Jrjn+aJENilyNB3ZS9jEcxrnGeCPZvYL4Gl3f8PMvg0s\nd/cDxO7Tb2atgOzYfe1x97VmtpNg5iqAtbG/cwiO8J+J3RgrypF3ShRJOB3ZixzF3W8FLgd2AT8x\ns1EEp24qbiQV+2VvahWbp/DxQdRHsb9Tgbfd/bPufi6QCwysYluRhFHYS9hEjveimaWa2WaCUzBz\ngCXAOcDLwBVmlmZmLQlmJ+oEbDGzYbFt+wKnAEVHDfsW0MHMBsSeX0fsXuki9UVhL2Fz3Nu8uvtB\ngqkVV5nZa8AFwIOxUzWrgfUEp2fmufvfCe7r/h0ze4NgtqphsVM90Upj7geuAuaa2eF7wX+rzjsT\nOQ7d4lhEJAR0ZC8iEgIKexGREFDYi4iEgMJeRCQEFPYiIiGgsBcRCQGFvYhICCjsRURC4P8DEJ20\nydWoxdgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7dd35bdad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Using XGboost\n",
    "#X_train = train_df.drop(\"Survived\",axis=1)\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "model = xgb.XGBClassifier(max_depth=10, n_estimators=300, learning_rate=0.05)\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(test_X)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33, random_state=7)\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 80.34%\n",
      "Iteration: 1\n",
      "Accuracy: 81.69%\n",
      "Iteration: 2\n",
      "Accuracy: 77.63%\n",
      "Iteration: 3\n",
      "Accuracy: 73.22%\n",
      "Iteration: 4\n",
      "Accuracy: 82.03%\n",
      "Iteration: 5\n",
      "Accuracy: 80.34%\n",
      "Iteration: 6\n",
      "Accuracy: 77.63%\n",
      "Iteration: 7\n",
      "Accuracy: 77.29%\n",
      "Iteration: 8\n",
      "Accuracy: 83.39%\n",
      "Iteration: 9\n",
      "Accuracy: 82.37%\n"
     ]
    }
   ],
   "source": [
    "# basic try at iterative training with XGboost\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "# fit model on all training data\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.05)\n",
    "\n",
    "for i in range(10):\n",
    "    print \"Iteration: \"+str(i)\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.93%\n",
      "Thresh=0.000, n=10, Accuracy: 77.97%\n",
      "Thresh=0.015, n=9, Accuracy: 77.97%\n",
      "Thresh=0.022, n=8, Accuracy: 77.97%\n",
      "Thresh=0.023, n=7, Accuracy: 78.98%\n",
      "Thresh=0.024, n=6, Accuracy: 78.98%\n",
      "Thresh=0.024, n=5, Accuracy: 80.00%\n",
      "Thresh=0.029, n=4, Accuracy: 76.61%\n",
      "Thresh=0.035, n=3, Accuracy: 69.83%\n",
      "Thresh=0.370, n=2, Accuracy: 69.15%\n",
      "Thresh=0.459, n=1, Accuracy: 57.63%\n"
     ]
    }
   ],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = train_X\n",
    "Y = train_y\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBClassifier(max_depth=10, n_estimators=300, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(X_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(X_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) \n",
    "\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "#X = train_X\n",
    "#Y = train_y\n",
    "# split data into train and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33\n",
    "optimized_GBM.fit(train_X, train_y)\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=1000, nthread=7,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'min_child_weight': [1, 3, 5], 'max_depth': [3, 5, 7]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
