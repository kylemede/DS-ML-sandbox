{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My playing with the Kaggle titanic challenge.\n",
    "\n",
    "I COPPIED THE INITIAL CODE and got lots of the ideas for this first Kaggle advanture from [here](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic/comments).\n",
    "\n",
    "I will later compact the important stuff from here into a kernal on my Kaggle account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\",dtype={\"Age\":np.float64},)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many ages\n",
    "train_df['Age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many ages are NaN?\n",
    "train_df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age =  29.6792717087\n"
     ]
    }
   ],
   "source": [
    "# plot ages of training data set, with NaN's removed\n",
    "if False:\n",
    "    train_df['Age'].dropna().astype(int).hist(bins=70)\n",
    "print 'Mean age = ',train_df['Age'].dropna().astype(int).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see where they got on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x=\"Embarked\",data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x='Survived',hue='Embarked',data=train_df,order=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so clearly there were more people who got on at S, and it seems their survival is disproportional.  Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    embark_survive_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "    sns.barplot(x='Embarked', y='Survived', data=embark_survive_perc,order=['S','C','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting, actually those from C had higher rate of survival.  So, knowing more people from your home town didn't help.\n",
    "\n",
    "## Next, did how much they paid have an effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_df['Fare'].astype(int).plot(kind='hist',bins=100, xlim=(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get fare for survived & didn't survive passengers \n",
    "if False:\n",
    "    fare_not_survived = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 0]\n",
    "    fare_survived     = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 1]\n",
    "\n",
    "    # get average and std for fare of survived/not survived passengers\n",
    "    avgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "    std_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "    avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
    "    avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before digging into how the ages factor in, let's take the advice of others and replace NaN's with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  80.0\n",
      "min:  0.42\n",
      "After this gaussian replacment, there are:  0\n",
      "max:  80.0\n",
      "min:  0.42\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = train_df['Age'].min(), train_df['Age'].max()\n",
    "mu, sigma = train_df[\"Age\"].mean(), train_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = train_df.shape[0]\n",
    "\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(train_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = train_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "train_df['Age'] = rands\n",
    "\n",
    "\"\"\"\n",
    "## we will make a new column with Nan's replaced, then push that into the original df\n",
    "n = train_df.shape[0] # number of rows\n",
    "#randy = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = n)\n",
    "# draw from a gaussian instead of simple uniform\n",
    "# note this uses a 'standard gauss' and that tneeds to have its var and mean shifted\n",
    "randy = np.random.randn(n)*std_age_train + average_age_train\n",
    "idx = np.isfinite(train_df['Age']) # gives a boolean index for the NaNs in the df's column\n",
    "randy[idx.values] = train_df[idx]['Age'].values  ## idexing the values of randy with this\n",
    "#now have updated column, next push into original df\n",
    "train_df['Age'] = randy\n",
    "\"\"\"\n",
    "\n",
    "print 'After this gaussian replacment, there are: ',train_df['Age'].isnull().sum()\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot new Age Values\n",
    "if False:\n",
    "    train_df['Age'].hist(bins=70)\n",
    "# Compare this to that from a few cells up for the raw ages with the NaN's dropped.  Not much different actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets perform the same NaN replacement for the 'Age' with the test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## let's pull in the test data\n",
    "test_df = pd.read_csv(\"test.csv\",dtype={\"Age\":np.float64},)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  76.0\n",
      "min:  0.17\n"
     ]
    }
   ],
   "source": [
    "#### Do the same for the test data\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = test_df['Age'].min(), test_df['Age'].max()\n",
    "mu, sigma = test_df[\"Age\"].mean(), test_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = test_df.shape[0]\n",
    "\n",
    "print 'max: ',test_df['Age'].max()\n",
    "print 'min: ',test_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(test_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = test_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "test_df['Age'] = rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df['Age'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's make a couple nice plots of survival vs age\n",
    "# peaks for survived/not survived passengers by their age\n",
    "if False:\n",
    "    facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\n",
    "    #facet.map(sns.kdeplot,'Age',shade= True) # This keeps crashing the kernal, but I don't know why!!!!!!!!!!\n",
    "    facet.set(xlim=(0, train_df['Age'].astype(int).max()))\n",
    "    facet.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average survived passengers by age\n",
    "if False:\n",
    "    fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "    average_age = train_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "    sns.barplot(x='Age', y='Survived', data=average_age)\n",
    "    print 'max: ',train_df['Age'].astype(int).max()\n",
    "    print 'min: ',train_df['Age'].astype(int).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
    "train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "test_df.drop(\"Cabin\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmede/miniconda2/envs/ExoSOFTcondaEnv/lib/python2.7/site-packages/pandas/core/indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Family\n",
    "\n",
    "# Instead of having two columns Parch & SibSp, \n",
    "# we can have only one column represent if the passenger had any family member aboard or not,\n",
    "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
    "train_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\n",
    "train_df['Family'].loc[train_df['Family'] > 0] = 1\n",
    "train_df['Family'].loc[train_df['Family'] == 0] = 0\n",
    "\n",
    "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
    "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
    "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
    "\n",
    "# drop Parch & SibSp\n",
    "train_df = train_df.drop(['SibSp','Parch'], axis=1)\n",
    "test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
    "\n",
    "# plot\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Family',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Family', data=train_df, order=[1,0], ax=axis1)\n",
    "\n",
    "    # average of survived for those who had/didn't have any family member\n",
    "    family_perc = train_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\n",
    "    sns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n",
    "\n",
    "    axis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "\n",
    "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as males, females, and child\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "train_df['Person'] = train_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# No need to use Sex column since we created Person column\n",
    "train_df.drop(['Sex'],axis=1,inplace=True)\n",
    "test_df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(train_df['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(person_dummies_titanic)\n",
    "test_df    = test_df.join(person_dummies_test)\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Person',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Person', data=train_df, ax=axis1)\n",
    "\n",
    "    # average of survived for each Person(male, female, or child)\n",
    "    person_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
    "    sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
    "\n",
    "train_df.drop(['Person'],axis=1,inplace=True)\n",
    "test_df.drop(['Person'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not surprising, woman and children had higher survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pclass\n",
    "\n",
    "# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\n",
    "if False:\n",
    "    sns.factorplot('Pclass','Survived',order=[1,2,3], data=train_df,size=5)\n",
    "\n",
    "# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n",
    "pclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train_df = train_df.join(pclass_dummies_titanic)\n",
    "test_df    = test_df.join(pclass_dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Title\n",
    "# a map of more aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                    }\n",
    "# we extract the title from each name\n",
    "train_df['Title'] = train_df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# we map each title\n",
    "train_df['Title'] = train_df.Title.map(Title_Dictionary)\n",
    "#train_df.head()\n",
    "# we extract the title from each name\n",
    "test_df['Title'] = test_df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# we map each title\n",
    "test_df['Title'] = test_df.Title.map(Title_Dictionary)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert categorical column values to ordinal for model fitting\n",
    "le_title = LabelEncoder()\n",
    "# To convert to ordinal:\n",
    "train_df.Title = le_title.fit_transform(train_df.Title)\n",
    "test_df.Title = le_title.fit_transform(test_df.Title)\n",
    "# To convert back to categorical:\n",
    "#train_df.Title = le_title.inverse_transform(train_df.Title)\n",
    "#train_df.head()\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also unsurprising.  The higher the booking class, then higher the chances to survive.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Now lets get to actually training and building a model to make predictions with!\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problems with the raw data\n",
    "- a couple NaNs in 'Embarked', so drop column\n",
    "- 'Name' strings can't be converted to anything useful, so drop column\n",
    "- replace NaNs in 'Fare' with median\n",
    "- 'Ticket' can't be converted to anything useful, so drop column\n",
    "- 'PassengerID' has no importance, so drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "# only for test_df, since there is a missing \"Fare\" values\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
    "train_df.drop(['Name'], axis=1,inplace=True)\n",
    "test_df.drop(['Name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Ticket'], axis=1,inplace=True)\n",
    "test_df.drop(['Ticket'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['PassengerId'], axis=1,inplace=True)\n",
    "#test_df.drop(['PassengerId'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "# Either to consider Embarked column in predictions,\n",
    "# and remove \"S\" dummy variable, \n",
    "# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n",
    "\n",
    "# OR, don't create dummy variables for Embarked column, just drop it, \n",
    "# because logically, Embarked doesn't seem to be useful in prediction.\n",
    "\n",
    "embark_dummies_train  = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_train.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n",
    "#embark_dummies_test.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(embark_dummies_train)\n",
    "test_df    = test_df.join(embark_dummies_test)\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The names are also pointless, so drop them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Title</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Family  Child  Female  Class_1  Class_2  Title  C  \\\n",
       "0         0  22.0   7.2500       1      0       0        0        0      2  0   \n",
       "1         1  38.0  71.2833       1      0       1        1        0      3  1   \n",
       "2         1  26.0   7.9250       0      0       1        0        0      1  0   \n",
       "3         1  35.0  53.1000       1      0       1        1        0      3  0   \n",
       "4         0  35.0   8.0500       0      0       0        0        0      2  0   \n",
       "\n",
       "   Q  S  \n",
       "0  0  1  \n",
       "1  0  0  \n",
       "2  0  1  \n",
       "3  0  1  \n",
       "4  0  1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Title</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age     Fare  Family  Child  Female  Class_1  Class_2  Title  \\\n",
       "0          892  34.5   7.8292       0      0       0        0        0      2   \n",
       "1          893  47.0   7.0000       1      0       1        0        0      3   \n",
       "2          894  62.0   9.6875       0      0       0        0        1      2   \n",
       "3          895  27.0   8.6625       0      0       0        0        0      2   \n",
       "4          896  22.0  12.2875       1      0       1        0        0      3   \n",
       "\n",
       "   C  Q  S  \n",
       "0  0  1  0  \n",
       "1  0  0  1  \n",
       "2  0  1  0  \n",
       "3  0  0  1  \n",
       "4  0  0  1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print '\\nFor train_df:'\n",
    "    for column in train_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(train_df[column].isnull().sum())\n",
    "        print 'min: ',train_df[column].min()\n",
    "        print 'max: ',train_df[column].max()\n",
    "\n",
    "    print '\\nFor test_df:'\n",
    "    for column in test_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(test_df[column].isnull().sum())\n",
    "        print 'min: ',test_df[column].min()\n",
    "        print 'max: ',test_df[column].max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "X_train = train_df.drop(\"Survived\",axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.80920314253647585)\n",
      "('cv score ', 0.80250482351605945)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('standard score ', logreg.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(logreg, X_train, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.8709315375982043)\n",
      "('cv score ', 0.66461128135285441)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = svc.predict(X_test)\n",
    "\n",
    "#svc.score(X_train, Y_train)\n",
    "print('standard score ', svc.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(svc, X_train, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.99102132435465773)\n",
      "('cv score ', 0.79693649982975823)\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print('standard score ', random_forest.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(random_forest, X_train, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-44bf5f2a4a33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnum_trees\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features,\n\u001b[0;32m     11\u001b[0m     min_samples_leaf=50)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "# From Comment by 'Ewald' at:\n",
    "# https://www.kaggle.com/c/job-salary-prediction/forums/t/4000/how-to-add-crossvalidation-to-scikit-randomforestregressor\n",
    "if True:\n",
    "    num_folds = 10\n",
    "    num_instances = len(X_train)\n",
    "    seed = 7\n",
    "    num_trees = 500\n",
    "    max_features = 'auto'\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features,\n",
    "    min_samples_leaf=50)\n",
    "    results= cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, n_jobs=-1)\n",
    "    print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.81705948372615034)\n",
      "('cv score ', 0.6635015889229372)\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors \n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "#knn.score(X_train, Y_train)\n",
    "\n",
    "print('standard score ', knn.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(knn, X_train, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.78002244668911336)\n",
      "('cv score ', 0.76240608330495974)\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "gaussian.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "\n",
    "#gaussian.score(X_train, Y_train)\n",
    "print('standard score ', gaussian.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(gaussian, X_train, Y_train, cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.019752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family</td>\n",
       "      <td>-0.126066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child</td>\n",
       "      <td>1.738955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.753647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>2.009490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>1.140570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>-0.099242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q</td>\n",
       "      <td>-0.280429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.786615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficient Estimate\n",
       "0      Age             -0.019752\n",
       "1     Fare              0.000800\n",
       "2   Family             -0.126066\n",
       "3    Child              1.738955\n",
       "4   Female              2.753647\n",
       "5  Class_1              2.009490\n",
       "6  Class_2              1.140570\n",
       "7        C             -0.099242\n",
       "8        Q             -0.280429\n",
       "9        S             -0.786615"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\": test_df[\"PassengerId\"],\n",
    "            \"Survived\": Y_pred\n",
    "        })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    ### Using XGboost\n",
    "    #X_train = train_df.drop(\"Survived\",axis=1)\n",
    "    train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "    train_y = train_df[\"Survived\"]\n",
    "    test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "    model = xgb.XGBClassifier(max_depth=10, n_estimators=300, learning_rate=0.05)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    # plot feature importance\n",
    "    plot_importance(model)\n",
    "    plt.show()\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33, random_state=7)\n",
    "    #accuracy = accuracy_score(y_test, predictions)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 80.34%\n",
      "Iteration: 1\n",
      "Accuracy: 73.90%\n",
      "Iteration: 2\n",
      "Accuracy: 77.63%\n",
      "Iteration: 3\n",
      "Accuracy: 80.00%\n",
      "Iteration: 4\n",
      "Accuracy: 81.36%\n",
      "Iteration: 5\n",
      "Accuracy: 78.64%\n",
      "Iteration: 6\n",
      "Accuracy: 80.00%\n",
      "Iteration: 7\n",
      "Accuracy: 77.63%\n",
      "Iteration: 8\n",
      "Accuracy: 80.68%\n",
      "Iteration: 9\n",
      "Accuracy: 81.36%\n"
     ]
    }
   ],
   "source": [
    "# basic try at iterative training with XGboost\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "# fit model on all training data\n",
    "acc = []\n",
    "mx_v = 0\n",
    "mx_e = 0\n",
    "ests = range(10,500,10)\n",
    "if False:\n",
    "    for est in ests:\n",
    "        #print est\n",
    "        model = xgb.XGBClassifier(max_depth=5, n_estimators=ests, learning_rate=0.05)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy *= 100.0\n",
    "        acc.append(accuracy)\n",
    "        #print(\"Accuracy: %.2f%%\" % (accuracy))\n",
    "        if acc[-1]>mx_v:\n",
    "            mx_v = acc[-1]\n",
    "            mx_e = est\n",
    "    print(\"maxes were: \",(mx_e,mx_v))\n",
    "\n",
    "    fig = plt.figure(figsize=(7,5))     \n",
    "    subPlot = fig.add_subplot(111)\n",
    "    subPlot.plot(ests,acc,linewidth=3)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.05)\n",
    "for i in range(10):\n",
    "    print \"Iteration: \"+str(i)\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.61%\n",
      "('It took: ', 5.418628931045532)\n"
     ]
    }
   ],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = train_X\n",
    "Y = train_y\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "if False:\n",
    "    thresholds = sort(model.feature_importances_)\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It took: ', 0.002824068069458008)\n"
     ]
    }
   ],
   "source": [
    "cv_params = {'max_depth': [3], 'min_child_weight': [1]}\n",
    "ind_params = {'learning_rate': 0.05, 'n_estimators': 100, 'nthread':100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), cv_params, \n",
    "                             scoring = 'accuracy', cv = 2, n_jobs = -1) \n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "\n",
    "#optimized_GBM.fit(train_X, train_y)\n",
    "\n",
    "#optimized_GBM.grid_scores_\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
