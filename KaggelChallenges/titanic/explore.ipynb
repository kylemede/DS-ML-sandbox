{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My playing with the Kaggle titanic challenge.\n",
    "\n",
    "I COPPIED THE INITIAL CODE and got lots of the ideas for this first Kaggle advanture from [here](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic/comments).\n",
    "\n",
    "I will later compact the important stuff from here into a kernal on my Kaggle account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\",dtype={\"Age\":np.float64},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many ages\n",
    "train_df['Age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many ages are NaN?\n",
    "train_df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age =  29.6792717087\n"
     ]
    }
   ],
   "source": [
    "# plot ages of training data set, with NaN's removed\n",
    "if False:\n",
    "    train_df['Age'].dropna().astype(int).hist(bins=70)\n",
    "print 'Mean age = ',train_df['Age'].dropna().astype(int).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see where they got on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x=\"Embarked\",data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sns.countplot(x='Survived',hue='Embarked',data=train_df,order=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so clearly there were more people who got on at S, and it seems their survival is disproportional.  Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    embark_survive_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "    sns.barplot(x='Embarked', y='Survived', data=embark_survive_perc,order=['S','C','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting, actually those from C had higher rate of survival.  So, knowing more people from your home town didn't help.\n",
    "\n",
    "## Next, did how much they paid have an effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_df['Fare'].astype(int).plot(kind='hist',bins=100, xlim=(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get fare for survived & didn't survive passengers \n",
    "if False:\n",
    "    fare_not_survived = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 0]\n",
    "    fare_survived     = train_df[\"Fare\"].astype(int)[train_df[\"Survived\"] == 1]\n",
    "\n",
    "    # get average and std for fare of survived/not survived passengers\n",
    "    avgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "    std_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "    avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
    "    avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before digging into how the ages factor in, let's take the advice of others and replace NaN's with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  80.0\n",
      "min:  0.42\n",
      "After this gaussian replacment, there are:  0\n",
      "max:  80.0\n",
      "min:  0.42\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = train_df['Age'].min(), train_df['Age'].max()\n",
    "mu, sigma = train_df[\"Age\"].mean(), train_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = train_df.shape[0]\n",
    "\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(train_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = train_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "train_df['Age'] = rands\n",
    "\n",
    "\"\"\"\n",
    "## we will make a new column with Nan's replaced, then push that into the original df\n",
    "n = train_df.shape[0] # number of rows\n",
    "#randy = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = n)\n",
    "# draw from a gaussian instead of simple uniform\n",
    "# note this uses a 'standard gauss' and that tneeds to have its var and mean shifted\n",
    "randy = np.random.randn(n)*std_age_train + average_age_train\n",
    "idx = np.isfinite(train_df['Age']) # gives a boolean index for the NaNs in the df's column\n",
    "randy[idx.values] = train_df[idx]['Age'].values  ## idexing the values of randy with this\n",
    "#now have updated column, next push into original df\n",
    "train_df['Age'] = randy\n",
    "\"\"\"\n",
    "\n",
    "print 'After this gaussian replacment, there are: ',train_df['Age'].isnull().sum()\n",
    "print 'max: ',train_df['Age'].max()\n",
    "print 'min: ',train_df['Age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot new Age Values\n",
    "if False:\n",
    "    train_df['Age'].hist(bins=70)\n",
    "# Compare this to that from a few cells up for the raw ages with the NaN's dropped.  Not much different actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets perform the same NaN replacement for the 'Age' with the test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## let's pull in the test data\n",
    "test_df = pd.read_csv(\"test.csv\",dtype={\"Age\":np.float64},)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  76.0\n",
      "min:  0.17\n"
     ]
    }
   ],
   "source": [
    "#### Do the same for the test data\n",
    "# column 'Age' has some NaN values\n",
    "# A simple approximation of the distribution of ages is a gaussian, but this is not commonly accurate.\n",
    "# lets make a vector of random ages centered on the mean, with a width of the std\n",
    "lower, upper = test_df['Age'].min(), test_df['Age'].max()\n",
    "mu, sigma = test_df[\"Age\"].mean(), test_df[\"Age\"].std()\n",
    "\n",
    "# number of rows\n",
    "n = test_df.shape[0]\n",
    "\n",
    "print 'max: ',test_df['Age'].max()\n",
    "print 'min: ',test_df['Age'].min()\n",
    "\n",
    "# vector of random values using the truncated normal distribution.  \n",
    "X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "rands = X.rvs(n)\n",
    "\n",
    "# get the indexes of the elements in the original array that are NaN\n",
    "idx = np.isfinite(test_df['Age'])\n",
    "\n",
    "# use the indexes to replace the NON-NaNs in the random array with the good values from the original array\n",
    "rands[idx.values] = test_df[idx]['Age'].values\n",
    "\n",
    "## At this point rands is now the cleaned column of data we wanted, so push it in to the original df\n",
    "test_df['Age'] = rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_df['Age'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's make a couple nice plots of survival vs age\n",
    "# peaks for survived/not survived passengers by their age\n",
    "if False:\n",
    "    facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\n",
    "    #facet.map(sns.kdeplot,'Age',shade= True) # This keeps crashing the kernal, but I don't know why!!!!!!!!!!\n",
    "    facet.set(xlim=(0, train_df['Age'].astype(int).max()))\n",
    "    facet.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average survived passengers by age\n",
    "if False:\n",
    "    fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "    average_age = train_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "    sns.barplot(x='Age', y='Survived', data=average_age)\n",
    "    print 'max: ',train_df['Age'].astype(int).max()\n",
    "    print 'min: ',train_df['Age'].astype(int).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
    "train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "test_df.drop(\"Cabin\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmede/miniconda2/envs/ExoSOFTcondaEnv/lib/python2.7/site-packages/pandas/core/indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Family\n",
    "\n",
    "# Instead of having two columns Parch & SibSp, \n",
    "# we can have only one column represent if the passenger had any family member aboard or not,\n",
    "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
    "train_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\n",
    "train_df['Family'].loc[train_df['Family'] > 0] = 1\n",
    "train_df['Family'].loc[train_df['Family'] == 0] = 0\n",
    "\n",
    "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
    "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
    "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
    "\n",
    "# drop Parch & SibSp\n",
    "train_df = train_df.drop(['SibSp','Parch'], axis=1)\n",
    "test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
    "\n",
    "# plot\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Family',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Family', data=train_df, order=[1,0], ax=axis1)\n",
    "\n",
    "    # average of survived for those who had/didn't have any family member\n",
    "    family_perc = train_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\n",
    "    sns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n",
    "\n",
    "    axis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "\n",
    "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as males, females, and child\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "train_df['Person'] = train_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# No need to use Sex column since we created Person column\n",
    "train_df.drop(['Sex'],axis=1,inplace=True)\n",
    "test_df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(train_df['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(person_dummies_titanic)\n",
    "test_df    = test_df.join(person_dummies_test)\n",
    "if False:\n",
    "    fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "    # sns.factorplot('Person',data=train_df,kind='count',ax=axis1)\n",
    "    sns.countplot(x='Person', data=train_df, ax=axis1)\n",
    "\n",
    "    # average of survived for each Person(male, female, or child)\n",
    "    person_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
    "    sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
    "\n",
    "train_df.drop(['Person'],axis=1,inplace=True)\n",
    "test_df.drop(['Person'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not surprising, woman and children had higher survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pclass\n",
    "\n",
    "# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\n",
    "if False:\n",
    "    sns.factorplot('Pclass','Survived',order=[1,2,3], data=train_df,size=5)\n",
    "\n",
    "# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n",
    "pclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train_df = train_df.join(pclass_dummies_titanic)\n",
    "test_df    = test_df.join(pclass_dummies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also unsurprising.  The higher the booking class, then higher the chances to survive.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "# Now lets get to actually training and building a model to make predictions with!\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problems with the raw data\n",
    "- a couple NaNs in 'Embarked', so drop column\n",
    "- 'Name' strings can't be converted to anything useful, so drop column\n",
    "- replace NaNs in 'Fare' with median\n",
    "- 'Ticket' can't be converted to anything useful, so drop column\n",
    "- 'PassengerID' has no importance, so drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "# only for test_df, since there is a missing \"Fare\" values\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
    "train_df.drop(['Name'], axis=1,inplace=True)\n",
    "test_df.drop(['Name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Ticket'], axis=1,inplace=True)\n",
    "test_df.drop(['Ticket'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['PassengerId'], axis=1,inplace=True)\n",
    "#test_df.drop(['PassengerId'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "# Either to consider Embarked column in predictions,\n",
    "# and remove \"S\" dummy variable, \n",
    "# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n",
    "\n",
    "# OR, don't create dummy variables for Embarked column, just drop it, \n",
    "# because logically, Embarked doesn't seem to be useful in prediction.\n",
    "\n",
    "embark_dummies_train  = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_train.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n",
    "#embark_dummies_test.drop(['S'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(embark_dummies_train)\n",
    "test_df    = test_df.join(embark_dummies_test)\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The names are also pointless, so drop them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Family  Child  Female  Class_1  Class_2  C  Q  S\n",
       "0         0  22.0   7.2500       1      0       0        0        0  0  0  1\n",
       "1         1  38.0  71.2833       1      0       1        1        0  1  0  0\n",
       "2         1  26.0   7.9250       0      0       1        0        0  0  0  1\n",
       "3         1  35.0  53.1000       1      0       1        1        0  0  0  1\n",
       "4         0  35.0   8.0500       0      0       0        0        0  0  0  1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age     Fare  Family  Child  Female  Class_1  Class_2  C  Q  \\\n",
       "0          892  34.5   7.8292       0      0       0        0        0  0  1   \n",
       "1          893  47.0   7.0000       1      0       1        0        0  0  0   \n",
       "2          894  62.0   9.6875       0      0       0        0        1  0  1   \n",
       "3          895  27.0   8.6625       0      0       0        0        0  0  0   \n",
       "4          896  22.0  12.2875       1      0       1        0        0  0  0   \n",
       "\n",
       "   S  \n",
       "0  0  \n",
       "1  1  \n",
       "2  0  \n",
       "3  1  \n",
       "4  1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print '\\nFor train_df:'\n",
    "    for column in train_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(train_df[column].isnull().sum())\n",
    "        print 'min: ',train_df[column].min()\n",
    "        print 'max: ',train_df[column].max()\n",
    "\n",
    "    print '\\nFor test_df:'\n",
    "    for column in test_df:\n",
    "        print \"# Nans in column '\"+column+\"' are: \"+str(test_df[column].isnull().sum())\n",
    "        print 'min: ',test_df[column].min()\n",
    "        print 'max: ',test_df[column].max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "X_train = train_df.drop(\"Survived\",axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.80246913580246915)\n",
      "('cv score ', 0.79125610032913407)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('standard score ', logreg.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(logreg, X_train, Y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('standard score ', 0.98877665544332216)\n",
      "('cv score ', 0.79582595619112484)\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print('standard score ', random_forest.score(X_train, Y_train))\n",
    "print('cv score ',np.mean(cross_val_score(random_forest, X_train, Y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.015973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family</td>\n",
       "      <td>-0.104255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child</td>\n",
       "      <td>1.632501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.666681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>1.811695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>1.075235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>-0.106409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q</td>\n",
       "      <td>-0.352060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.741163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Coefficient Estimate\n",
       "0      Age             -0.015973\n",
       "1     Fare              0.001136\n",
       "2   Family             -0.104255\n",
       "3    Child              1.632501\n",
       "4   Female              2.666681\n",
       "5  Class_1              1.811695\n",
       "6  Class_2              1.075235\n",
       "7        C             -0.106409\n",
       "8        Q             -0.352060\n",
       "9        S             -0.741163"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\": test_df[\"PassengerId\"],\n",
    "            \"Survived\": Y_pred\n",
    "        })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    ### Using XGboost\n",
    "    #X_train = train_df.drop(\"Survived\",axis=1)\n",
    "    train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "    train_y = train_df[\"Survived\"]\n",
    "    test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "    model = xgb.XGBClassifier(max_depth=10, n_estimators=300, learning_rate=0.05)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    # plot feature importance\n",
    "    plot_importance(model)\n",
    "    plt.show()\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33, random_state=7)\n",
    "    #accuracy = accuracy_score(y_test, predictions)\n",
    "    #print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('maxes were: ', (180, 85.084745762711862))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAE5CAYAAAAnVK9fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa83094bcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic try at iterative training with XGboost\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "# fit model on all training data\n",
    "acc = []\n",
    "mx_v = 0\n",
    "mx_e = 0\n",
    "ests = range(10,500,10)\n",
    "if False:\n",
    "    for est in ests:\n",
    "        #print est\n",
    "        model = xgb.XGBClassifier(max_depth=5, n_estimators=ests, learning_rate=0.05)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy *= 100.0\n",
    "        acc.append(accuracy)\n",
    "        #print(\"Accuracy: %.2f%%\" % (accuracy))\n",
    "        if acc[-1]>mx_v:\n",
    "            mx_v = acc[-1]\n",
    "            mx_e = est\n",
    "    print(\"maxes were: \",(mx_e,mx_v))\n",
    "\n",
    "    fig = plt.figure(figsize=(7,5))     \n",
    "    subPlot = fig.add_subplot(111)\n",
    "    subPlot.plot(ests,acc,linewidth=3)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(2):\n",
    "        print \"Iteration: \"+str(i)\n",
    "        # split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.33)#, random_state=7)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.27%\n",
      "('It took: ', 4.69061803817749)\n"
     ]
    }
   ],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "# load data\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = train_X\n",
    "Y = train_y\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "if False:\n",
    "    thresholds = sort(model.feature_importances_)\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier(max_depth=10, nthread=100, n_estimators=300, learning_rate=0.05)\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3], 'min_child_weight': [1]}\n",
    "ind_params = {'learning_rate': 0.05, 'n_estimators': 100, 'nthread':100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), cv_params, \n",
    "                             scoring = 'accuracy', cv = 2, n_jobs = -1) \n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "train_X = train_df.drop(\"Survived\",axis=1).as_matrix()\n",
    "train_y = train_df[\"Survived\"]\n",
    "test_X = test_df.drop(\"PassengerId\",axis=1).copy().as_matrix()\n",
    "#X = train_X\n",
    "#Y = train_y\n",
    "# split data into train and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33\n",
    "optimized_GBM.fit(train_X, train_y)\n",
    "\n",
    "optimized_GBM.grid_scores_\n",
    "toc = timeit.default_timer()\n",
    "print(\"It took: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
